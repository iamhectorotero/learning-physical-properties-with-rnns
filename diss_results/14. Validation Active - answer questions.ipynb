{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "from toddler.action_coding import mass_answers, force_answers\n",
    "from toddler.models import ValueNetwork\n",
    "from toddler.RecurrentWorker import train\n",
    "from toddler.validate import validate\n",
    "\n",
    "from isaac.models import ComplexRNNModel\n",
    "\n",
    "from toddler.simulator.config import generate_every_world_configuration, generate_cond\n",
    "\n",
    "from generate_passive_simulations import get_configuration_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_directory = \"models/answer_questions/\"\n",
    "data_directory = \"answer_questions_plots/\"\n",
    "\n",
    "question_type = \"mass\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "from isaac.utils import get_cuda_device_if_available, create_directory\n",
    "device = get_cuda_device_if_available()\n",
    "print(device)\n",
    "\n",
    "create_directory(data_directory)\n",
    "create_directory(model_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_WORLDS 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "discount_factor = 0.95\n",
    "\n",
    "every_conf = generate_every_world_configuration()\n",
    "every_world_answer = np.array(list(map(get_configuration_answer, every_conf)))\n",
    "n_configurations = len(every_conf)\n",
    "\n",
    "train_size = 0.7\n",
    "val_size = 0.15\n",
    "test_size = 0.15\n",
    "\n",
    "all_indices = np.arange(n_configurations)\n",
    "train_indices, not_train_indices = train_test_split(all_indices, train_size=train_size,\n",
    "                                                    random_state=0, stratify=every_world_answer)\n",
    "val_indices, test_indices = train_test_split(not_train_indices, train_size=0.5,                \n",
    "                                             random_state=0,\n",
    "                                             stratify=every_world_answer[not_train_indices])\n",
    "\n",
    "N_WORLDS = 100\n",
    "timeout = 1800\n",
    "print(\"N_WORLDS\", N_WORLDS)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "repeated_val_indices = np.random.choice(val_indices, N_WORLDS, replace=True)\n",
    "val_cond = generate_cond(every_conf[repeated_val_indices])\n",
    "\n",
    "experience_replay = ()\n",
    "agent_answers = ()\n",
    "\n",
    "n_bodies = 2\n",
    "action_repeat = 1\n",
    "starting_step = 0\n",
    "starting_episode = 0\n",
    "\n",
    "if question_type == \"mass\":\n",
    "    force_answers = {}\n",
    "else:\n",
    "    mass_answers = {}\n",
    "\n",
    "for cond in val_cond:\n",
    "    cond[\"timeout\"] = timeout\n",
    "    if question_type == \"mass\":\n",
    "        cond[\"lf\"] = [[0, 0], [0, 0]]\n",
    "    cond[\"svs\"] = [{'y': 0, 'x': 0} for _ in range(n_bodies)]\n",
    "\n",
    "\n",
    "validation_dfs = []\n",
    "for seed in [0, 42, 72]:\n",
    "    \n",
    "    this_seed_model_directory = model_directory + question_type + \"/\" + str(seed) + \"/\"\n",
    "    \n",
    "    for model in tqdm(glob.glob(this_seed_model_directory+\"*_model\")):\n",
    "        episode_number = model.split(\"/\")[-1].split(\"_\")[0]\n",
    "    \n",
    "        net_params = {\"input_dim\":17, \"hidden_dim\":25, \"n_layers\":4, \"output_dim\":9, \"dropout\":0.0}\n",
    "        value_network = ValueNetwork(**net_params).to(torch.device(device))\n",
    "        value_network.load_state_dict(torch.load(model))\n",
    "        optimizer = optim.Adam(value_network.parameters(), lr=5e-4)\n",
    "\n",
    "        agent_cond = val_cond\n",
    "\n",
    "        valArgs = {\"value_network\": value_network, \"val_cond\": agent_cond, \n",
    "                   \"timeout\": timeout, \"n_bodies\": n_bodies,\n",
    "                   \"action_repeat\": action_repeat, \"print_stats\":False,\n",
    "                   \"device\": device, \"reward_control\": False, \"done_with_control\": False, \n",
    "                    \"reward_not_controlling_negatively\": True, \"reward_not_answering_negatively\": True, \n",
    "                    \"possible_actions\": np.arange(0, 9), \"mouse_exploration_frames\": 300, \n",
    "                    \"mass_answers\": mass_answers, \"force_answers\": force_answers, \"return_replays\": True,\n",
    "                    \"force_answer_at_t\": (timeout - 1)}\n",
    "\n",
    "        validation_data, replays = validate(**valArgs)\n",
    "        \n",
    "        \n",
    "        for i, replay in enumerate(replays):\n",
    "            replay.to_hdf(this_seed_model_directory+episode_number+\"_replays.h5\", key=\"replay_\"+str(i))\n",
    "        \n",
    "        validation_data = {stat+\"_\"+attr: [f(validation_data[attr])] for attr in [\"control\", \"episode_length\", \"answers\"] \n",
    "                           for stat, f in zip([\"avg\", \"std\"], [np.mean, np.std])}\n",
    "        \n",
    "        df = pd.DataFrame.from_dict(validation_data)\n",
    "        df[\"seed\"] = seed\n",
    "        df[\"episode\"] = episode_number\n",
    "        validation_dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7903e02eb595>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvalidation_dfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_dfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvalidation_dfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_hdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_directory\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"validation_data.h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"validation_data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/diss/lib/python3.5/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    223\u001b[0m                        \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                        copy=copy, sort=sort)\n\u001b[0m\u001b[1;32m    226\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/diss/lib/python3.5/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No objects to concatenate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "validation_dfs = pd.concat(validation_dfs)\n",
    "validation_dfs.to_hdf(data_directory+\"validation_data.h5\", key=\"validation_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dfs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
