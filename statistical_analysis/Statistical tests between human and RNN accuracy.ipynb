{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question to be answered:\n",
    "\n",
    "- Is the accuracy of model/human significantly better? In both force and mass questions?\n",
    "- Is the distribution of responses significantly different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from isaac.utils import get_cuda_device_if_available\n",
    "import joblib\n",
    "\n",
    "from isaac.dataset import read_dataset, prepare_dataset\n",
    "from isaac.models import MultiBranchModel\n",
    "from isaac.constants import BASIC_TRAINING_COLS, MASS_CLASS_COLS, FORCE_CLASS_COLS\n",
    "from isaac.training import evaluate_saved_model\n",
    "from isaac.statistical_tests import z_test\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = get_cuda_device_if_available()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_question_accuracy(question_type):\n",
    "    normalise_data = True\n",
    "    scaler_path = \"dissertation_results/scalers/passive_dual_scaler.sk\"\n",
    "    network_dims = (len(BASIC_TRAINING_COLS), 25, 3, 0.5)\n",
    "    model_path = \"dissertation_results/models/passive_\"+question_type+\"_dual_model.pt\"\n",
    "    dataset_path = \"data/passive_trials_exp1.h5\"\n",
    "    class_columns = [list(MASS_CLASS_COLS), list(FORCE_CLASS_COLS)]\n",
    "    multiclass = True\n",
    "    seq_end = 1800\n",
    "    step_size = 3\n",
    "\n",
    "    accuracies, predicted = evaluate_saved_model(model_path, network_dims, dataset_path, \n",
    "                                                 training_columns=BASIC_TRAINING_COLS, class_columns=class_columns, \n",
    "                                                 step_size=step_size, seq_end=seq_end, scaler_path=scaler_path,\n",
    "                                                 arch=MultiBranchModel, multiclass=multiclass)\n",
    "\n",
    "    mass_accuracy, force_accuracy = accuracies\n",
    "    mass_predicted = predicted[:, 0]\n",
    "    force_predicted = predicted[:, 1]\n",
    "    \n",
    "    if question_type == \"mass\":\n",
    "        return mass_accuracy, mass_predicted\n",
    "    \n",
    "    return force_accuracy, force_predicted\n",
    "\n",
    "def get_participant_accuracy(passive_responses, answer_column, question_type_answer):\n",
    "    return [(df[answer_column] == df[question_type_answer]).sum() / len(df) \n",
    "            for participant_id, df in passive_responses.groupby(\"participant\")]\n",
    "\n",
    "\n",
    "def get_participant_accuracy_filtering_by_answer(passive_responses, answer_column, question_type_answer, filter_by_class):\n",
    "    \n",
    "    passive_responses = passive_responses.copy().query(question_type_answer+\" == \"+filter_by_class)\n",
    "    \n",
    "    return [(df[answer_column] == df[question_type_answer]).sum() / len(df) \n",
    "            for participant_id, df in passive_responses.groupby(\"participant\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T-test for MASS questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model's predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator StandardScaler from version 0.21.2 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "100%|██████████| 264/264 [00:01<00:00, 138.76it/s]\n",
      "100%|██████████| 264/264 [00:00<00:00, 622.65it/s]\n",
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator StandardScaler from version 0.21.2 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "  5%|▍         | 13/264 [00:00<00:01, 128.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [56.06060606 62.87878788]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 264/264 [00:01<00:00, 152.39it/s]\n",
      "100%|██████████| 264/264 [00:00<00:00, 671.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [56.43939394 59.46969697]\n"
     ]
    }
   ],
   "source": [
    "question_type = \"mass\"\n",
    "acc, model_mass_predicted = get_question_accuracy(question_type)\n",
    "question_type = \"force\"\n",
    "acc2, model_force_predicted = get_question_accuracy(question_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56.06060606060606, 59.46969696969697)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, acc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mass_answers = [MASS_CLASS_COLS[i] for i in model_mass_predicted]\n",
    "model_force_answers = [FORCE_CLASS_COLS[i] for i in model_force_predicted]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load human results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning: Warning messages:\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning: 1: \n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning: In value[[3L]](cond) :\n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning: \n",
      " \n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning:  \"getThreads\" not available for .C() for package \"RevoUtilsMath\"\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning: 2: \n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning: 3: \n",
      "  warnings.warn(x, RRuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from rpy2.robjects import r, pandas2ri\n",
    "pandas2ri.activate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/rpy2/robjects/pandas2ri.py:191: FutureWarning: from_items is deprecated. Please use DataFrame.from_dict(dict(items), ...) instead. DataFrame.from_dict(OrderedDict(items)) may be used to preserve the key order.\n",
      "  res = PandasDataFrame.from_items(items)\n"
     ]
    }
   ],
   "source": [
    "rdata_path = \"data/experiment1.rdata\"\n",
    "r['load'](rdata_path)\n",
    "\n",
    "is_passive = (r['df.l'].condition == '0')\n",
    "responses = r['df.l'][[\"participant\", \"mass\", \"relationship\", \"trueMass\", \"trueRelationship\", 'post_ent_rel', 'post_ent_mass']]\n",
    "passive_responses = responses[is_passive]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "passive_responses[\"model_mass\"] = model_mass_answers\n",
    "passive_responses[\"model_relationship\"] = model_force_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  3,  6,  7, 11, 13, 15, 19, 23, 25, 27, 29, 31, 32, 34, 39, 40,\n",
       "       41, 47, 48, 54, 56, 58, 60])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passive_responses.participant.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_mass_accuracy_list = get_participant_accuracy(passive_responses, \"mass\", \"trueMass\")\n",
    "human_force_accuracy_list = get_participant_accuracy(passive_responses, \"relationship\", \"trueRelationship\")\n",
    "\n",
    "model_mass_accuracy_list = get_participant_accuracy(passive_responses, \"model_mass\", \"trueMass\")\n",
    "model_force_accuracy_list = get_participant_accuracy(passive_responses, \"model_relationship\", \"trueRelationship\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43560606060606055 ± 0.14840559109211918\n",
      "0.5606060606060606 ± 0.1499923475244192\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(human_mass_accuracy_list), \"±\", np.std(human_mass_accuracy_list))\n",
    "print(np.mean(model_mass_accuracy_list), \"±\", np.std(model_mass_accuracy_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5946969696969697 ± 0.15741359663015264\n",
      "0.6022727272727272 ± 0.21450901719345106\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(model_force_accuracy_list), \"±\", np.std(model_force_accuracy_list))\n",
    "print(np.mean(human_force_accuracy_list), \"±\", np.std(human_force_accuracy_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform t-test on overall accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null hypothesis (opposite of what we want to prove): accuracies are not significantly different\n",
    "# Alternative hypothesis: accuracies are significantly different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind, ttest_rel, f_oneway"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is the model significantly better answering mass questions than humans?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=-2.5410778355110044, pvalue=0.018257011838468833)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_rel(human_mass_accuracy_list, model_mass_accuracy_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is the model significantly better answering force questions than humans?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=0.14062873191761607, pvalue=0.8893876174537672)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_rel(human_force_accuracy_list, model_force_accuracy_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is the model significantly better answering force questions than mass questions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-0.7519322605334596, pvalue=0.4559221487681704)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_ind(model_mass_accuracy_list, model_force_accuracy_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform z-test on overall accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null hypothesis (opposite of what we want to prove): accuracies are not significantly different\n",
    "# Alternative hypothesis: classifier 2 is significantly more accurate than the first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "z_zero_point_five = 1.645"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z = z_test(passive_responses[\"trueMass\"], passive_responses[\"mass\"], passive_responses[\"model_mass\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(Z)\n",
    "if Z < -z_zero_point_five:\n",
    "    print(\"Classifier two significantly better than classifier one.\")\n",
    "else:\n",
    "    print(\"Classifier two not significantly better.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z = z_test(passive_responses[\"trueRelationship\"], passive_responses[\"relationship\"], passive_responses[\"model_relationship\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(Z)\n",
    "if Z < -z_zero_point_five:\n",
    "    print(\"Classifier two significantly better than classifier one.\")\n",
    "else:\n",
    "    print(\"Classifier two not significantly better than classifier one.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Are correct guesses / errors correlated between humans and model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chisquare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "passive_responses[\"human_mass_correct_guesses\"] = (passive_responses[\"mass\"] == passive_responses[\"trueMass\"])\n",
    "passive_responses[\"human_force_correct_guesses\"] = (passive_responses[\"relationship\"] == passive_responses[\"trueRelationship\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "passive_responses[\"model_mass_correct_guesses\"] = (passive_responses[\"model_mass\"] == passive_responses[\"trueMass\"])\n",
    "passive_responses[\"model_force_correct_guesses\"] = (passive_responses[\"model_relationship\"] == passive_responses[\"trueRelationship\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_coincidence = get_participant_accuracy(passive_responses, \"mass\", \"model_mass\")\n",
    "force_coincidence = get_participant_accuracy(passive_responses, \"relationship\", \"model_relationship\")\n",
    "\n",
    "print(np.mean(mass_coincidence), np.std(mass_coincidence))\n",
    "print(np.mean(force_coincidence), np.std(force_coincidence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_for_independence(first_answers, second_answers):\n",
    "    both_correct = (first_answers & second_answers).sum()\n",
    "    both_wrong = (~first_answers & ~second_answers).sum()\n",
    "    first_correct_second_wrong = (~first_answers & second_answers).sum()\n",
    "    first_wrong_second_correct = (first_answers & ~second_answers).sum()\n",
    "    \n",
    "    matrix = [[both_correct, model_correct_human_wrong], [model_wrong_human_correct, both_wrong]]\n",
    "    chisquare_results = chisquare(matrix, axis=None)\n",
    "    \n",
    "    return matrix, chisquare_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[94, 63], [65, 42]],\n",
       " Power_divergenceResult(statistic=20.757575757575758, pvalue=0.00011821240002149164))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_for_independence(passive_responses[\"human_force_correct_guesses\"], passive_responses[\"model_force_correct_guesses\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[65, 63], [65, 66]],\n",
       " Power_divergenceResult(statistic=0.07335907335907335, pvalue=0.99483034234225))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_for_independence(passive_responses[\"human_mass_correct_guesses\"], passive_responses[\"model_mass_correct_guesses\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_for_coincidence(first_answers, second_answers):\n",
    "    \n",
    "    matrix = []\n",
    "    all_classes = first_answers.unique()\n",
    "    \n",
    "    for class_name in all_classes:\n",
    "        this_class_coincidences = []\n",
    "        for second_class_name in all_classes:\n",
    "            n_coincidences = ((first_answers == class_name) & (second_answers == second_class_name)).sum()\n",
    "            this_class_coincidences.append(n_coincidences)\n",
    "            \n",
    "        matrix.append(this_class_coincidences)\n",
    "    \n",
    "    chisquare_results = chisquare(matrix, axis=None)\n",
    "    \n",
    "    return matrix, chisquare_results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[23, 23, 39], [27, 39, 20], [24, 21, 48]],\n",
       " Power_divergenceResult(statistic=27.47727272727273, pvalue=0.0005845625172034362))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_for_coincidence(passive_responses[\"mass\"], passive_responses[\"model_mass\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[56, 25, 40], [32, 37, 7], [24, 9, 34]],\n",
       " Power_divergenceResult(statistic=63.81818181818182, pvalue=8.261900559100757e-11))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_for_coincidence(passive_responses[\"relationship\"], passive_responses[\"model_relationship\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Are correct guesses / errors correlated to informativeness?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mass responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=0.01279904562116854, pvalue=0.910067041455921)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_not_na = ~(passive_responses[\"post_ent_mass\"].isna())\n",
    "\n",
    "not_na_passive_responses = passive_responses[is_not_na]\n",
    "post_mass_correct_guesses = not_na_passive_responses[not_na_passive_responses.model_mass_correct_guesses].post_ent_mass\n",
    "post_mass_wrong_guesses = not_na_passive_responses[~not_na_passive_responses.model_mass_correct_guesses].post_ent_mass\n",
    "\n",
    "f_oneway(post_mass_correct_guesses, post_mass_wrong_guesses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=0.006737936877802744, pvalue=0.934681767921192)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_mass_correct_guesses = not_na_passive_responses[not_na_passive_responses.human_mass_correct_guesses].post_ent_mass\n",
    "post_mass_wrong_guesses = not_na_passive_responses[~not_na_passive_responses.human_mass_correct_guesses].post_ent_mass\n",
    "\n",
    "f_oneway(post_mass_correct_guesses, post_mass_wrong_guesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Force responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=5.518325262971857, pvalue=0.020039887109630675)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_force_correct_guesses = not_na_passive_responses[not_na_passive_responses.model_force_correct_guesses].post_ent_rel\n",
    "post_force_wrong_guesses = not_na_passive_responses[~not_na_passive_responses.model_force_correct_guesses].post_ent_rel\n",
    "\n",
    "f_oneway(post_force_correct_guesses, post_force_wrong_guesses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=6.152748062725771, pvalue=0.014155734767664217)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_force_correct_guesses = not_na_passive_responses[not_na_passive_responses.human_force_correct_guesses].post_ent_rel\n",
    "post_force_wrong_guesses = not_na_passive_responses[~not_na_passive_responses.human_force_correct_guesses].post_ent_rel\n",
    "\n",
    "f_oneway(post_force_correct_guesses, post_force_wrong_guesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is the model better at predicting any force class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "repel_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"model_relationship\", \n",
    "                                                                   \"trueRelationship\", \"'repel'\")\n",
    "\n",
    "none_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"model_relationship\", \n",
    "                                                                   \"trueRelationship\", \"'none'\")\n",
    "\n",
    "attract_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"model_relationship\", \n",
    "                                                                   \"trueRelationship\", \"'attract'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5972222222222222 0.2718109137608462\n",
      "0.5666666666666668 0.23570226039551584\n",
      "0.6388888888888888 0.2873355675774611\n",
      "\n",
      "Ttest_indResult(statistic=0.40731024949571437, pvalue=0.685669440130222)\n",
      "Ttest_indResult(statistic=-0.5052132657565751, pvalue=0.6158211993432529)\n",
      "Ttest_indResult(statistic=0.9319889226569723, pvalue=0.3562082784594377)\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(repel_accuracy_list), np.std(repel_accuracy_list))\n",
    "print(np.mean(none_accuracy_list), np.std(none_accuracy_list))\n",
    "print(np.mean(attract_accuracy_list), np.std(attract_accuracy_list))\n",
    "\n",
    "print()\n",
    "\n",
    "print(ttest_ind(repel_accuracy_list, none_accuracy_list))\n",
    "print(ttest_ind(repel_accuracy_list, attract_accuracy_list))\n",
    "print(ttest_ind(attract_accuracy_list, none_accuracy_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is the model better at predicting any mass class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"model_mass\", \n",
    "                                                                   \"trueMass\", \"'A'\")\n",
    "\n",
    "same_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"model_mass\", \n",
    "                                                                   \"trueMass\", \"'same'\")\n",
    "\n",
    "b_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"model_mass\", \n",
    "                                                                   \"trueMass\", \"'B'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666 0.1717960677340692\n",
      "0.40625 0.26821652478299446\n",
      "0.625 0.26020824993326663\n",
      "\n",
      "Ttest_indResult(statistic=3.921011546884571, pvalue=0.00029150727723554646)\n",
      "Ttest_indResult(statistic=0.6408699444616551, pvalue=0.5247872789047803)\n",
      "Ttest_indResult(statistic=2.8073330548972777, pvalue=0.007303420602440454)\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(a_accuracy_list), np.std(a_accuracy_list))\n",
    "print(np.mean(same_accuracy_list), np.std(same_accuracy_list))\n",
    "print(np.mean(b_accuracy_list), np.std(b_accuracy_list))\n",
    "\n",
    "print()\n",
    "\n",
    "print(ttest_ind(a_accuracy_list, same_accuracy_list))\n",
    "print(ttest_ind(a_accuracy_list, b_accuracy_list))\n",
    "print(ttest_ind(b_accuracy_list, same_accuracy_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is the model better at predicting any force class than humans?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5277777777777778 0.3458305443885759\n",
      "0.6166666666666667 0.2576604138956718\n",
      "0.6527777777777778 0.29626012510696587\n"
     ]
    }
   ],
   "source": [
    "human_repel_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"relationship\", \n",
    "                                                                         \"trueRelationship\", \"'repel'\")\n",
    "\n",
    "human_none_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"relationship\", \n",
    "                                                                        \"trueRelationship\", \"'none'\")\n",
    "\n",
    "human_attract_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"relationship\", \n",
    "                                                                   \"trueRelationship\", \"'attract'\")\n",
    "\n",
    "print(np.mean(human_repel_accuracy_list), np.std(human_repel_accuracy_list))\n",
    "print(np.mean(human_none_accuracy_list), np.std(human_none_accuracy_list))\n",
    "print(np.mean(human_attract_accuracy_list), np.std(human_attract_accuracy_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_relResult(statistic=0.6790483458299109, pvalue=0.5038838059771544)\n",
      "Ttest_relResult(statistic=-0.7429670248402688, pvalue=0.46502329616012295)\n",
      "Ttest_relResult(statistic=-0.17052013832006113, pvalue=0.8660922491049519)\n"
     ]
    }
   ],
   "source": [
    "print(ttest_rel(repel_accuracy_list, human_repel_accuracy_list))\n",
    "print(ttest_rel(none_accuracy_list, human_none_accuracy_list))\n",
    "print(ttest_rel(attract_accuracy_list, human_attract_accuracy_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is the model better at predicting any mass class than humans?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4791666666666667 0.21550167568309583\n",
      "0.3541666666666667 0.3054766312211496\n",
      "0.4861111111111111 0.33304385578560547\n",
      "\n"
     ]
    }
   ],
   "source": [
    "human_a_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"mass\", \n",
    "                                                                     \"trueMass\", \"'A'\")\n",
    "\n",
    "human_same_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"mass\", \n",
    "                                                                        \"trueMass\", \"'same'\")\n",
    "\n",
    "human_b_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"mass\", \n",
    "                                                                     \"trueMass\", \"'B'\")\n",
    "\n",
    "print(np.mean(human_a_accuracy_list), np.std(human_a_accuracy_list))\n",
    "print(np.mean(human_same_accuracy_list), np.std(human_same_accuracy_list))\n",
    "print(np.mean(human_b_accuracy_list), np.std(human_b_accuracy_list))\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_relResult(statistic=3.1906626065525105, pvalue=0.0040684049186777696)\n",
      "Ttest_relResult(statistic=0.6026892774303364, pvalue=0.5526120908127179)\n",
      "Ttest_relResult(statistic=1.6830069266853707, pvalue=0.10590104861701705)\n"
     ]
    }
   ],
   "source": [
    "print(ttest_rel(a_accuracy_list, human_a_accuracy_list))\n",
    "print(ttest_rel(same_accuracy_list, human_same_accuracy_list))\n",
    "print(ttest_rel(b_accuracy_list, human_b_accuracy_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
