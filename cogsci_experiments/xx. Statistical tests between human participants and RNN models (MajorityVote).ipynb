{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question to be answered:\n",
    "\n",
    "- Is the accuracy of model/human significantly better? In both force and mass questions?\n",
    "- Is the distribution of responses significantly different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import isaac.constants\n",
    "isaac.constants.TQDM_DISABLE = True\n",
    "\n",
    "from torch import nn\n",
    "from isaac.utils import get_cuda_device_if_available\n",
    "import joblib\n",
    "\n",
    "from isaac.dataset import read_dataset, prepare_dataset\n",
    "from isaac.models import MultiBranchModel\n",
    "from isaac.constants import BASIC_TRAINING_COLS, MASS_CLASS_COLS, FORCE_CLASS_COLS\n",
    "from isaac.evaluation import evaluate_saved_model\n",
    "from isaac.statistical_tests import z_test\n",
    "\n",
    "import torch\n",
    "import glob\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = get_cuda_device_if_available()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RTHETA_ATTRS = [obj+\".\"+attr for obj in [\"o1\", \"o2\", \"o3\", \"o4\"] for attr in [\"x\", \"y\", \"r\", \"theta\"]]\n",
    "\n",
    "def add_r_theta_attributes(trials):\n",
    "    for trial in tqdm(trials):\n",
    "        for obj in [\"o1\", \"o2\", \"o3\", \"o4\"]:\n",
    "            trial[obj+\".r\"] = (trial[obj+\".vx\"]**2 + trial[obj+\".vy\"]**2)**0.5\n",
    "            trial[obj+\".theta\"] = (np.arctan2(trial[obj+\".vx\"], trial[obj+\".vy\"]) * 180 / np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_question_accuracy_for_group_of_models(question_type):\n",
    "    normalise_data = True\n",
    "    scaler_path = \"scalers/passive_dual_scaler.sk\"\n",
    "    network_dims = (len(BASIC_TRAINING_COLS), 25, 3, 0.5)\n",
    "    dataset_path = \"../new_exp_data/exp7_passive.h5\"\n",
    "    class_columns = [list(MASS_CLASS_COLS), list(FORCE_CLASS_COLS)]\n",
    "    multiclass = True\n",
    "    seq_end = 2700\n",
    "    step_size = 3\n",
    "    \n",
    "    models = sorted(glob.glob(\"models/train_25_mb/best_\"+question_type+\"_model_seed_*.pt\"))\n",
    "\n",
    "    group_accuracy = []\n",
    "    group_predictions = []\n",
    "    \n",
    "    # trials = read_dataset(dataset_path)\n",
    "    # add_r_theta_attributes(trials)\n",
    "\n",
    "    for model_path in tqdm(models):\n",
    "        accuracies, predicted = evaluate_saved_model(model_path, network_dims, dataset_path, \n",
    "                                                     training_columns=BASIC_TRAINING_COLS, class_columns=class_columns, \n",
    "                                                     step_size=step_size, seq_end=seq_end, scaler_path=scaler_path,\n",
    "                                                     arch=MultiBranchModel, multiclass=multiclass, trials=None)\n",
    "\n",
    "        if question_type == \"mass\":\n",
    "            accuracy = accuracies[0]\n",
    "            predicted = predicted[:, 0]\n",
    "        else:\n",
    "            accuracy = accuracies[1]\n",
    "            predicted = predicted[:, 1]\n",
    "\n",
    "        group_accuracy.append(accuracy)\n",
    "        group_predictions.append(predicted.numpy())\n",
    "\n",
    "    return group_accuracy, group_predictions\n",
    "\n",
    "def get_participant_accuracy(passive_responses, answer_column, question_type_answer):\n",
    "    return [(df[answer_column] == df[question_type_answer]).sum() / len(df) \n",
    "            for _, df in passive_responses.groupby(\"cond_worldvar\")]\n",
    "\n",
    "def get_participant_accuracy_filtering_by_answer(passive_responses, answer_column, question_type_answer, filter_by_class):\n",
    "    \n",
    "    passive_responses = passive_responses.copy().query(question_type_answer+\" == \"+filter_by_class)\n",
    "    \n",
    "    return [(df[answer_column] == df[question_type_answer]).sum() / len(df) \n",
    "            for _, df in passive_responses.groupby(\"cond_worldvar\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T-test for MASS questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model's predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 1/25 [00:01<00:25,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [69.44444444 63.88888889]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 2/25 [00:01<00:22,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [52.77777778 75.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 3/25 [00:02<00:19,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [50.         72.22222222]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 4/25 [00:03<00:18,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [69.44444444 63.88888889]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 5/25 [00:04<00:17,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [63.88888889 61.11111111]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 6/25 [00:05<00:17,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [52.77777778 72.22222222]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 7/25 [00:06<00:18,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [52.77777778 61.11111111]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 8/25 [00:07<00:17,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [50.         55.55555556]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 9/25 [00:08<00:16,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [47.22222222 52.77777778]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 10/25 [00:09<00:16,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [47.22222222 63.88888889]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 11/25 [00:10<00:15,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [50.         77.77777778]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 12/25 [00:12<00:14,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [55.55555556 77.77777778]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 13/25 [00:13<00:12,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [58.33333333 52.77777778]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 14/25 [00:13<00:10,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [61.11111111 75.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 15/25 [00:14<00:09,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [50.         63.88888889]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 16/25 [00:15<00:08,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [55.55555556 61.11111111]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 17/25 [00:16<00:07,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [41.66666667 66.66666667]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 18/25 [00:17<00:06,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [66.66666667 69.44444444]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 19/25 [00:18<00:05,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [50.         55.55555556]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 20/25 [00:18<00:04,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [52.77777778 66.66666667]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 21/25 [00:19<00:03,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [41.66666667 72.22222222]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 22/25 [00:20<00:02,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [52.77777778 58.33333333]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 23/25 [00:21<00:01,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [50.         61.11111111]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 24/25 [00:21<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [41.66666667 58.33333333]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:22<00:00,  1.33it/s]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [58.33333333 75.        ]\n",
      "\n",
      "FORCE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 1/25 [00:00<00:18,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [69.44444444 69.44444444]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 2/25 [00:01<00:17,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [66.66666667 69.44444444]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 3/25 [00:02<00:16,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [50.         72.22222222]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 4/25 [00:02<00:15,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [58.33333333 66.66666667]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 5/25 [00:03<00:14,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [61.11111111 66.66666667]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 6/25 [00:04<00:14,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [55.55555556 63.88888889]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 7/25 [00:05<00:13,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [55.55555556 69.44444444]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 8/25 [00:05<00:12,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [55.55555556 50.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 9/25 [00:06<00:11,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [44.44444444 58.33333333]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 10/25 [00:07<00:11,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [44.44444444 58.33333333]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 11/25 [00:08<00:10,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [58.33333333 72.22222222]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 12/25 [00:08<00:09,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [63.88888889 63.88888889]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 13/25 [00:09<00:08,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [55.55555556 61.11111111]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 14/25 [00:10<00:08,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [52.77777778 80.55555556]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 15/25 [00:11<00:07,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [61.11111111 61.11111111]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 16/25 [00:11<00:06,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [55.55555556 63.88888889]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 17/25 [00:12<00:06,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [58.33333333 66.66666667]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 18/25 [00:13<00:05,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [66.66666667 69.44444444]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 19/25 [00:14<00:04,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [52.77777778 61.11111111]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 20/25 [00:15<00:03,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [52.77777778 66.66666667]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 21/25 [00:15<00:03,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [41.66666667 75.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 22/25 [00:16<00:02,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [61.11111111 58.33333333]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 23/25 [00:17<00:01,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [52.77777778 61.11111111]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 24/25 [00:18<00:00,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [44.44444444 61.11111111]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 25/25 [00:19<00:00,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [58.33333333 75.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"MASS\")\n",
    "question_type = \"mass\"\n",
    "group_mass_acc, group_mass_prediction = get_question_accuracy_for_group_of_models(question_type)\n",
    "     \n",
    "print(\"\\nFORCE\")\n",
    "question_type = \"force\"\n",
    "group_force_acc, group_force_prediction = get_question_accuracy_for_group_of_models(question_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_mass_prediction = np.array(group_mass_prediction)\n",
    "group_force_prediction = np.array(group_force_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []\n",
    "for question_i in range(group_mass_prediction.shape[1]):\n",
    "    \n",
    "    mass_predictions = list(group_mass_prediction[:, question_i])\n",
    "    question_mass_answers = [(key, mass_predictions.count(key)) for key in range(3)]\n",
    "    question_mass_answers = sorted(question_mass_answers, key=lambda x: x[1], reverse=True)\n",
    "    question_mass_answers = np.hstack(question_mass_answers)\n",
    "    \n",
    "    force_predictions = list(group_force_prediction[:, question_i])\n",
    "    question_force_answers = [(key, force_predictions.count(key)) for key in range(3)]\n",
    "    question_force_answers = sorted(question_force_answers, key=lambda x: x[1], reverse=True)\n",
    "    question_force_answers = np.hstack(question_force_answers)\n",
    "    \n",
    "    answers.append(np.hstack((question_mass_answers, question_force_answers)))\n",
    "    \n",
    "\n",
    "model_answers_df = pd.DataFrame(data=answers, \n",
    "                                columns=[\"model_first_mass_resp\", \"model_first_mass_count\", \n",
    "                                         \"model_second_mass_resp\", \"model_second_mass_count\",\n",
    "                                         \"model_third_mass_resp\", \"model_third_mass_count\",\n",
    "                                         \"model_first_rel_resp\", \"model_first_rel_count\", \n",
    "                                         \"model_second_rel_resp\", \"model_second_rel_count\",\n",
    "                                         \"model_third_rel_resp\", \"model_third_rel_count\"\n",
    "                                         ])\n",
    "\n",
    "model_answers_df = model_answers_df.fillna(0)\n",
    "\n",
    "mass_answer_id_to_str = lambda x: MASS_CLASS_COLS[int(x)]\n",
    "rel_answer_id_to_str = lambda x: FORCE_CLASS_COLS[int(x)]\n",
    "\n",
    "model_answers_df.model_first_mass_resp = model_answers_df.model_first_mass_resp.apply(mass_answer_id_to_str)\n",
    "model_answers_df.model_second_mass_resp = model_answers_df.model_second_mass_resp.apply(mass_answer_id_to_str)\n",
    "model_answers_df.model_third_mass_resp = model_answers_df.model_third_mass_resp.apply(mass_answer_id_to_str)\n",
    "\n",
    "model_answers_df.model_first_rel_resp = model_answers_df.model_first_rel_resp.apply(rel_answer_id_to_str)\n",
    "model_answers_df.model_second_rel_resp = model_answers_df.model_second_rel_resp.apply(rel_answer_id_to_str)\n",
    "model_answers_df.model_third_rel_resp = model_answers_df.model_third_rel_resp.apply(rel_answer_id_to_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_first_mass_resp</th>\n",
       "      <th>model_first_mass_count</th>\n",
       "      <th>model_second_mass_resp</th>\n",
       "      <th>model_second_mass_count</th>\n",
       "      <th>model_third_mass_resp</th>\n",
       "      <th>model_third_mass_count</th>\n",
       "      <th>model_first_rel_resp</th>\n",
       "      <th>model_first_rel_count</th>\n",
       "      <th>model_second_rel_resp</th>\n",
       "      <th>model_second_rel_count</th>\n",
       "      <th>model_third_rel_resp</th>\n",
       "      <th>model_third_rel_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>same</td>\n",
       "      <td>14</td>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>attract</td>\n",
       "      <td>16</td>\n",
       "      <td>none</td>\n",
       "      <td>9</td>\n",
       "      <td>repel</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>24</td>\n",
       "      <td>same</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>attract</td>\n",
       "      <td>14</td>\n",
       "      <td>none</td>\n",
       "      <td>10</td>\n",
       "      <td>repel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>12</td>\n",
       "      <td>same</td>\n",
       "      <td>12</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>attract</td>\n",
       "      <td>23</td>\n",
       "      <td>none</td>\n",
       "      <td>2</td>\n",
       "      <td>repel</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>16</td>\n",
       "      <td>same</td>\n",
       "      <td>9</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>repel</td>\n",
       "      <td>17</td>\n",
       "      <td>none</td>\n",
       "      <td>8</td>\n",
       "      <td>attract</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>same</td>\n",
       "      <td>15</td>\n",
       "      <td>A</td>\n",
       "      <td>7</td>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>none</td>\n",
       "      <td>22</td>\n",
       "      <td>attract</td>\n",
       "      <td>3</td>\n",
       "      <td>repel</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_first_mass_resp  model_first_mass_count model_second_mass_resp  \\\n",
       "0                  same                      14                      A   \n",
       "1                     A                      24                   same   \n",
       "2                     B                      12                   same   \n",
       "3                     B                      16                   same   \n",
       "4                  same                      15                      A   \n",
       "\n",
       "   model_second_mass_count model_third_mass_resp  model_third_mass_count  \\\n",
       "0                       10                     B                       1   \n",
       "1                        1                     B                       0   \n",
       "2                       12                     A                       1   \n",
       "3                        9                     A                       0   \n",
       "4                        7                     B                       3   \n",
       "\n",
       "  model_first_rel_resp  model_first_rel_count model_second_rel_resp  \\\n",
       "0              attract                     16                  none   \n",
       "1              attract                     14                  none   \n",
       "2              attract                     23                  none   \n",
       "3                repel                     17                  none   \n",
       "4                 none                     22               attract   \n",
       "\n",
       "   model_second_rel_count model_third_rel_resp  model_third_rel_count  \n",
       "0                       9                repel                      0  \n",
       "1                      10                repel                      1  \n",
       "2                       2                repel                      0  \n",
       "3                       8              attract                      0  \n",
       "4                       3                repel                      0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_answers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_world_variant = []\n",
    "world_id = []\n",
    "\n",
    "for condition_id in range(4, 0, -1):\n",
    "    filename = \"../new_exp_data/physics_data%d.json\" % condition_id\n",
    "    fd = open(filename)\n",
    "    sim_data = json.load(fd)\n",
    "    \n",
    "    for sim in sim_data:\n",
    "        if sim[\"practice\"]:\n",
    "            continue\n",
    "        condition_world_variant.append(sim[\"condition_world_variant\"])\n",
    "        world_id.append(sim[\"world_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_answers_df[\"condition_world_variant\"] = condition_world_variant\n",
    "model_answers_df[\"world_id\"] = world_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_first_mass_resp</th>\n",
       "      <th>model_first_mass_count</th>\n",
       "      <th>model_second_mass_resp</th>\n",
       "      <th>model_second_mass_count</th>\n",
       "      <th>model_third_mass_resp</th>\n",
       "      <th>model_third_mass_count</th>\n",
       "      <th>model_first_rel_resp</th>\n",
       "      <th>model_first_rel_count</th>\n",
       "      <th>model_second_rel_resp</th>\n",
       "      <th>model_second_rel_count</th>\n",
       "      <th>model_third_rel_resp</th>\n",
       "      <th>model_third_rel_count</th>\n",
       "      <th>condition_world_variant</th>\n",
       "      <th>world_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>same</td>\n",
       "      <td>14</td>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>attract</td>\n",
       "      <td>16</td>\n",
       "      <td>none</td>\n",
       "      <td>9</td>\n",
       "      <td>repel</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>24</td>\n",
       "      <td>same</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>attract</td>\n",
       "      <td>14</td>\n",
       "      <td>none</td>\n",
       "      <td>10</td>\n",
       "      <td>repel</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>12</td>\n",
       "      <td>same</td>\n",
       "      <td>12</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>attract</td>\n",
       "      <td>23</td>\n",
       "      <td>none</td>\n",
       "      <td>2</td>\n",
       "      <td>repel</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>16</td>\n",
       "      <td>same</td>\n",
       "      <td>9</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>repel</td>\n",
       "      <td>17</td>\n",
       "      <td>none</td>\n",
       "      <td>8</td>\n",
       "      <td>attract</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>same</td>\n",
       "      <td>15</td>\n",
       "      <td>A</td>\n",
       "      <td>7</td>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>none</td>\n",
       "      <td>22</td>\n",
       "      <td>attract</td>\n",
       "      <td>3</td>\n",
       "      <td>repel</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_first_mass_resp  model_first_mass_count model_second_mass_resp  \\\n",
       "0                  same                      14                      A   \n",
       "1                     A                      24                   same   \n",
       "2                     B                      12                   same   \n",
       "3                     B                      16                   same   \n",
       "4                  same                      15                      A   \n",
       "\n",
       "   model_second_mass_count model_third_mass_resp  model_third_mass_count  \\\n",
       "0                       10                     B                       1   \n",
       "1                        1                     B                       0   \n",
       "2                       12                     A                       1   \n",
       "3                        9                     A                       0   \n",
       "4                        7                     B                       3   \n",
       "\n",
       "  model_first_rel_resp  model_first_rel_count model_second_rel_resp  \\\n",
       "0              attract                     16                  none   \n",
       "1              attract                     14                  none   \n",
       "2              attract                     23                  none   \n",
       "3                repel                     17                  none   \n",
       "4                 none                     22               attract   \n",
       "\n",
       "   model_second_rel_count model_third_rel_resp  model_third_rel_count  \\\n",
       "0                       9                repel                      0   \n",
       "1                      10                repel                      1   \n",
       "2                       2                repel                      0   \n",
       "3                       8              attract                      0   \n",
       "4                       3                repel                      0   \n",
       "\n",
       "   condition_world_variant  world_id  \n",
       "0                        4       148  \n",
       "1                        4      1282  \n",
       "2                        4      1732  \n",
       "3                        4       470  \n",
       "4                        4       740  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_answers_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load human results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning: Warning messages:\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning: 1: \n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning: In value[[3L]](cond) :\n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning: \n",
      " \n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning:  \"getThreads\" not available for .C() for package \"RevoUtilsMath\"\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning: 2: \n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning: 3: \n",
      "  warnings.warn(x, RRuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from rpy2.robjects import r, pandas2ri\n",
    "pandas2ri.activate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/rpy2/robjects/pandas2ri.py:191: FutureWarning: from_items is deprecated. Please use DataFrame.from_dict(dict(items), ...) instead. DataFrame.from_dict(OrderedDict(items)) may be used to preserve the key order.\n",
      "  res = PandasDataFrame.from_items(items)\n"
     ]
    }
   ],
   "source": [
    "rdata_path = \"../new_exp_data/e7_passive.rdata\"\n",
    "r['load'](rdata_path)\n",
    "\n",
    "responses = r[\"tw\"].query(\"practice == 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Percentage of participants that get an answer right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "passive_responses = []\n",
    "\n",
    "for name, df in responses.groupby([\"cond_worldvar\", \"world_id\", \"true_mass\", \"true_rel\"]):\n",
    "    response = [name[0], name[1], name[2], name[3]]\n",
    "\n",
    "    value_counts = df.resp_rel.value_counts()\n",
    "    for i in range(len(value_counts)):\n",
    "        answer = value_counts.index[i]\n",
    "        response.append(answer)\n",
    "        \n",
    "        if answer == name[3]:\n",
    "            got_it_right = value_counts[i]\n",
    "    response.append(got_it_right / value_counts.sum())\n",
    "            \n",
    "    value_counts = df.resp_mass.value_counts()\n",
    "    for i in range(len(value_counts)):\n",
    "        answer = value_counts.index[i]\n",
    "        response.append(answer)\n",
    "        if answer == name[2]:\n",
    "            got_it_right = value_counts[i]\n",
    "            \n",
    "    response.append(got_it_right / value_counts.sum())\n",
    "        \n",
    "    passive_responses.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "passive_responses = pd.DataFrame(data=passive_responses, \n",
    "                                 columns=[\"cond_worldvar\", \"world_id\", \"true_mass\", \"true_rel\",  \n",
    "                                          \"resp_rel\", \"second_resp_rel\", \"third_resp_rel\", \"got_rel_right\",\n",
    "                                          \"resp_mass\", \"second_resp_mass\", \"third_resp_mass\", \"got_mass_right\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cond_worldvar</th>\n",
       "      <th>world_id</th>\n",
       "      <th>true_mass</th>\n",
       "      <th>true_rel</th>\n",
       "      <th>resp_rel</th>\n",
       "      <th>second_resp_rel</th>\n",
       "      <th>third_resp_rel</th>\n",
       "      <th>got_rel_right</th>\n",
       "      <th>resp_mass</th>\n",
       "      <th>second_resp_mass</th>\n",
       "      <th>third_resp_mass</th>\n",
       "      <th>got_mass_right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1218</td>\n",
       "      <td>A</td>\n",
       "      <td>repel</td>\n",
       "      <td>repel</td>\n",
       "      <td>attract</td>\n",
       "      <td>none</td>\n",
       "      <td>0.76</td>\n",
       "      <td>A</td>\n",
       "      <td>same</td>\n",
       "      <td>B</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1736</td>\n",
       "      <td>B</td>\n",
       "      <td>none</td>\n",
       "      <td>repel</td>\n",
       "      <td>none</td>\n",
       "      <td>attract</td>\n",
       "      <td>0.40</td>\n",
       "      <td>B</td>\n",
       "      <td>same</td>\n",
       "      <td>A</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1758</td>\n",
       "      <td>B</td>\n",
       "      <td>repel</td>\n",
       "      <td>repel</td>\n",
       "      <td>attract</td>\n",
       "      <td>none</td>\n",
       "      <td>0.44</td>\n",
       "      <td>B</td>\n",
       "      <td>same</td>\n",
       "      <td>A</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1819</td>\n",
       "      <td>B</td>\n",
       "      <td>attract</td>\n",
       "      <td>attract</td>\n",
       "      <td>repel</td>\n",
       "      <td>none</td>\n",
       "      <td>0.64</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>same</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>438</td>\n",
       "      <td>same</td>\n",
       "      <td>repel</td>\n",
       "      <td>repel</td>\n",
       "      <td>none</td>\n",
       "      <td>attract</td>\n",
       "      <td>0.56</td>\n",
       "      <td>B</td>\n",
       "      <td>same</td>\n",
       "      <td>A</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cond_worldvar world_id true_mass true_rel resp_rel second_resp_rel  \\\n",
       "0             1     1218         A    repel    repel         attract   \n",
       "1             1     1736         B     none    repel            none   \n",
       "2             1     1758         B    repel    repel         attract   \n",
       "3             1     1819         B  attract  attract           repel   \n",
       "4             1      438      same    repel    repel            none   \n",
       "\n",
       "  third_resp_rel  got_rel_right resp_mass second_resp_mass third_resp_mass  \\\n",
       "0           none           0.76         A             same               B   \n",
       "1        attract           0.40         B             same               A   \n",
       "2           none           0.44         B             same               A   \n",
       "3           none           0.64         B                A            same   \n",
       "4        attract           0.56         B             same               A   \n",
       "\n",
       "   got_mass_right  \n",
       "0            0.52  \n",
       "1            0.52  \n",
       "2            0.72  \n",
       "3            0.60  \n",
       "4            0.36  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passive_responses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "passive_responses[\"cond_worldvar\"] = passive_responses[\"cond_worldvar\"].astype(\"int64\")\n",
    "passive_responses[\"world_id\"] = passive_responses[\"world_id\"].astype(\"int64\")\n",
    "\n",
    "passive_responses = passive_responses.merge(model_answers_df, left_on=[\"cond_worldvar\", \"world_id\"], right_on=[\"condition_world_variant\", \"world_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Percentage of models that get an answer right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_that_got_mass_question_right = []\n",
    "\n",
    "for i, answer in enumerate(passive_responses.true_mass):\n",
    "    if passive_responses.model_first_mass_resp.iloc[i] == answer:\n",
    "        models_that_got_mass_question_right.append(passive_responses.model_first_mass_count.iloc[i])\n",
    "    elif passive_responses.model_second_mass_resp.iloc[i] == answer:\n",
    "        models_that_got_mass_question_right.append(passive_responses.model_second_mass_count.iloc[i])\n",
    "    elif passive_responses.model_third_mass_resp.iloc[i] == answer:\n",
    "        models_that_got_mass_question_right.append(passive_responses.model_third_mass_count.iloc[i])\n",
    "\n",
    "        \n",
    "models_that_got_rel_question_right = []\n",
    "        \n",
    "for i, answer in enumerate(passive_responses.true_rel):\n",
    "    if passive_responses.model_first_rel_resp.iloc[i] == answer:\n",
    "        models_that_got_rel_question_right.append(passive_responses.model_first_rel_count.iloc[i])\n",
    "        \n",
    "    elif passive_responses.model_second_rel_resp.iloc[i] == answer:\n",
    "        models_that_got_rel_question_right.append(passive_responses.model_second_rel_count.iloc[i])\n",
    "        \n",
    "    elif passive_responses.model_third_rel_resp.iloc[i] == answer:\n",
    "        models_that_got_rel_question_right.append(passive_responses.model_third_rel_count.iloc[i])\n",
    "        \n",
    "\n",
    "passive_responses[\"models_got_mass_right\"] = np.array(models_that_got_mass_question_right) / 25\n",
    "passive_responses[\"models_got_rel_right\"] = np.array(models_that_got_rel_question_right) / 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cond_worldvar', 'world_id', 'true_mass', 'true_rel', 'resp_rel',\n",
       "       'second_resp_rel', 'third_resp_rel', 'got_rel_right', 'resp_mass',\n",
       "       'second_resp_mass', 'third_resp_mass', 'got_mass_right',\n",
       "       'model_first_mass_resp', 'model_first_mass_count',\n",
       "       'model_second_mass_resp', 'model_second_mass_count',\n",
       "       'model_third_mass_resp', 'model_third_mass_count',\n",
       "       'model_first_rel_resp', 'model_first_rel_count',\n",
       "       'model_second_rel_resp', 'model_second_rel_count',\n",
       "       'model_third_rel_resp', 'model_third_rel_count',\n",
       "       'condition_world_variant', 'models_got_mass_right',\n",
       "       'models_got_rel_right'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passive_responses.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "passive_responses[\"model_mass\"] = passive_responses[\"model_first_mass_resp\"]\n",
    "passive_responses[\"model_relationship\"] = passive_responses[\"model_first_rel_resp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_mass_accuracy_list = get_participant_accuracy(passive_responses, \"resp_mass\", \"true_mass\")\n",
    "human_force_accuracy_list = get_participant_accuracy(passive_responses, \"resp_rel\", \"true_rel\")\n",
    "\n",
    "model_mass_accuracy_list = get_participant_accuracy(passive_responses, \"model_mass\", \"true_mass\")\n",
    "model_force_accuracy_list = get_participant_accuracy(passive_responses, \"model_relationship\", \"true_rel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3888888888888889 ± 0.16666666666666669\n",
      "0.5555555555555556 ± 0.13608276348795437\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(human_mass_accuracy_list), \"±\", np.std(human_mass_accuracy_list))\n",
    "print(np.mean(model_mass_accuracy_list), \"±\", np.std(model_mass_accuracy_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8055555555555555 ± 0.0921284663987611\n",
      "0.8055555555555555 ± 0.0921284663987611\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(human_force_accuracy_list), \"±\", np.std(human_force_accuracy_list))\n",
    "print(np.mean(model_force_accuracy_list), \"±\", np.std(model_force_accuracy_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform t-test on overall accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null hypothesis (opposite of what we want to prove): accuracies are not significantly different\n",
    "# Alternative hypothesis: accuracies are significantly different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind, ttest_rel, f_oneway"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is the model significantly better answering mass questions than humans?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=-1.5666989036012806, pvalue=0.21516994256954994)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_rel(human_mass_accuracy_list, model_mass_accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=-3.6873191331691264, pvalue=0.000763240022957818)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_rel(passive_responses.got_mass_right, passive_responses.models_got_mass_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is the model significantly better answering force questions than humans?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=0.0, pvalue=1.0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_rel(human_force_accuracy_list, model_force_accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=-2.364560857365549, pvalue=0.023727816753575937)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_rel(passive_responses.got_rel_right, passive_responses.models_got_rel_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is the model significantly better answering force questions than mass questions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-2.6349301969610384, pvalue=0.03880272569471035)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_ind(model_mass_accuracy_list, model_force_accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-1.9991187485802633, pvalue=0.049479134569990736)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_ind(passive_responses.models_got_mass_right, passive_responses.models_got_rel_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Are correct guesses / errors correlated between humans and model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chisquare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "passive_responses[\"model_mass_correct_guesses\"] = (passive_responses[\"model_mass\"] == passive_responses[\"true_mass\"])\n",
    "passive_responses[\"model_force_correct_guesses\"] = (passive_responses[\"model_relationship\"] == passive_responses[\"true_rel\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "passive_responses[\"corRel\"] = (passive_responses[\"resp_rel\"] == passive_responses[\"true_rel\"])\n",
    "passive_responses[\"corMass\"] = (passive_responses[\"resp_mass\"] == passive_responses[\"true_mass\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49999999999999994 0.12422599874998831\n",
      "0.6111111111111112 0.055555555555555525\n"
     ]
    }
   ],
   "source": [
    "mass_coincidence = get_participant_accuracy(passive_responses, \"resp_mass\", \"model_mass\")\n",
    "force_coincidence = get_participant_accuracy(passive_responses, \"resp_rel\", \"model_relationship\")\n",
    "\n",
    "print(np.mean(mass_coincidence), np.std(mass_coincidence))\n",
    "print(np.mean(force_coincidence), np.std(force_coincidence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_for_independence(first_answers, second_answers):\n",
    "    both_correct = (first_answers & second_answers).sum()\n",
    "    both_wrong = (~first_answers & ~second_answers).sum()\n",
    "    first_correct_second_wrong = (first_answers & ~second_answers).sum()\n",
    "    first_wrong_second_correct = (~first_answers & second_answers).sum()\n",
    "    matrix = np.array([[both_correct, first_correct_second_wrong], [first_wrong_second_correct, both_wrong]])\n",
    "    \n",
    "    accuracy_first = first_answers.sum() / len(first_answers)\n",
    "    accuracy_sec = second_answers.sum() / len(second_answers)\n",
    "    total_answers = len(first_answers)\n",
    "    \n",
    "    \n",
    "    expected_first = np.array([[accuracy_first/2, accuracy_first/2], [(1 - accuracy_first)/2, (1 - accuracy_first)/2]])\n",
    "    expected_sec = np.array([[accuracy_sec/2, (1 - accuracy_sec)/2], [accuracy_sec/2, (1 - accuracy_sec)/2]])\n",
    "    expected = expected_first * expected_sec\n",
    "    expected /= np.sum(expected)\n",
    "    expected *= total_answers\n",
    "    \n",
    "    chisquare_results = chisquare(matrix, expected, axis=None)\n",
    "    print(\"Expected\")\n",
    "    print(expected)\n",
    "    print(\"Reality\")\n",
    "    print(matrix)\n",
    "    return chisquare_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected\n",
      "[[23.36111111  5.63888889]\n",
      " [ 5.63888889  1.36111111]]\n",
      "Reality\n",
      "[[22  7]\n",
      " [ 7  0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=2.097502972651607, pvalue=0.5524180941443271)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_for_independence(passive_responses[\"corRel\"], passive_responses[\"model_force_correct_guesses\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected\n",
      "[[ 7.77777778  6.22222222]\n",
      " [12.22222222  9.77777778]]\n",
      "Reality\n",
      "[[10  4]\n",
      " [10 12]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=2.337662337662338, pvalue=0.505344223349651)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_for_independence(passive_responses[\"corMass\"], passive_responses[\"model_mass_correct_guesses\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_for_coincidence(first_answers, second_answers, true_answers):\n",
    "    \n",
    "    matrix = []\n",
    "    all_classes = sorted(first_answers.unique())\n",
    "    \n",
    "    for class_name in all_classes:\n",
    "        this_class_coincidences = []\n",
    "        for second_class_name in all_classes:\n",
    "            n_coincidences = ((first_answers == class_name) & (second_answers == second_class_name)).sum()\n",
    "            this_class_coincidences.append(n_coincidences)\n",
    "            \n",
    "        matrix.append(this_class_coincidences)\n",
    "    \n",
    "    matrix = np.array(matrix)\n",
    "    \n",
    "    expected = []    \n",
    "    for class_name in all_classes:\n",
    "        this_class_prob = []\n",
    "        for second_class_name in all_classes:\n",
    "            prob = 0\n",
    "            for true_class in all_classes:\n",
    "                # p_humans(first_class\\true_class) * p_rnn(first_class\\true_class)\n",
    "                class_examples = (true_answers == true_class).sum()\n",
    "                \n",
    "                p_class = class_examples / len(first_answers)\n",
    "                p_first_given_class = ((first_answers == class_name) & (true_answers == true_class)).sum() / class_examples\n",
    "                p_second_given_class = ((second_answers == second_class_name) & (true_answers == true_class)).sum() / class_examples\n",
    "                val = p_class * p_first_given_class * p_second_given_class\n",
    "                \n",
    "                prob += val\n",
    "\n",
    "            this_class_prob.append(prob)\n",
    "        expected.append(this_class_prob)\n",
    "    expected = np.array(expected) \n",
    "    expected /= np.sum(expected)\n",
    "    expected *= len(first_answers)\n",
    "    print(\"Expected:\")\n",
    "    print(all_classes)\n",
    "    print(expected)\n",
    "    print()\n",
    "    print(\"Reality:\")\n",
    "    print(all_classes)\n",
    "    print(matrix)\n",
    "    chisquare_results = chisquare(matrix, expected, axis=None)\n",
    "    \n",
    "    return chisquare_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected:\n",
      "['attract', 'none', 'repel']\n",
      "[[11.          3.75        0.25      ]\n",
      " [ 0.          5.91666667  1.08333333]\n",
      " [ 0.          7.33333333  6.66666667]]\n",
      "\n",
      "Reality:\n",
      "['attract', 'none', 'repel']\n",
      "[[11  4  0]\n",
      " [ 0  5  2]\n",
      " [ 0  8  6]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/scipy/stats/stats.py:4567: RuntimeWarning: invalid value encountered in true_divide\n",
      "  terms = (f_obs - f_exp)**2 / f_exp\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=nan, pvalue=nan)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_for_coincidence(passive_responses[\"resp_rel\"], passive_responses[\"model_relationship\"], passive_responses[\"true_rel\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected:\n",
      "['A', 'B', 'same']\n",
      "[[5.41666667 4.33333333 7.25      ]\n",
      " [3.33333333 5.83333333 4.83333333]\n",
      " [1.25       1.83333333 1.91666667]]\n",
      "\n",
      "Reality:\n",
      "['A', 'B', 'same']\n",
      "[[7 3 7]\n",
      " [2 8 4]\n",
      " [1 1 3]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=3.4045777311144625, pvalue=0.9064678812856377)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_for_coincidence(passive_responses[\"resp_mass\"], passive_responses[\"model_mass\"], passive_responses[\"true_mass\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is the model better at predicting any force class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "repel_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"model_relationship\", \n",
    "                                                                   \"true_rel\", \"'repel'\")\n",
    "\n",
    "none_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"model_relationship\", \n",
    "                                                                   \"true_rel\", \"'none'\")\n",
    "\n",
    "attract_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"model_relationship\", \n",
    "                                                                   \"true_rel\", \"'attract'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5833333333333333 0.14433756729740643\n",
      "0.9166666666666666 0.14433756729740646\n",
      "0.9166666666666666 0.14433756729740646\n",
      "\n",
      "Ttest_indResult(statistic=-2.8284271247461903, pvalue=0.030019745287544374)\n",
      "Ttest_indResult(statistic=-2.8284271247461903, pvalue=0.030019745287544374)\n",
      "Ttest_indResult(statistic=0.0, pvalue=1.0)\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(repel_accuracy_list), np.std(repel_accuracy_list))\n",
    "print(np.mean(none_accuracy_list), np.std(none_accuracy_list))\n",
    "print(np.mean(attract_accuracy_list), np.std(attract_accuracy_list))\n",
    "\n",
    "print()\n",
    "\n",
    "print(ttest_ind(repel_accuracy_list, none_accuracy_list))\n",
    "print(ttest_ind(repel_accuracy_list, attract_accuracy_list))\n",
    "print(ttest_ind(attract_accuracy_list, none_accuracy_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is the model better at predicting any mass class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"model_mass\", \n",
    "                                                                   \"true_mass\", \"'A'\")\n",
    "\n",
    "same_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"model_mass\", \n",
    "                                                                   \"true_mass\", \"'same'\")\n",
    "\n",
    "b_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"model_mass\", \n",
    "                                                                   \"true_mass\", \"'B'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41666666666666663 0.2763853991962833\n",
      "0.41666666666666663 0.14433756729740646\n",
      "0.8333333333333333 0.16666666666666669\n",
      "\n",
      "Ttest_indResult(statistic=0.0, pvalue=1.0)\n",
      "Ttest_indResult(statistic=-2.23606797749979, pvalue=0.06670680196204087)\n",
      "Ttest_indResult(statistic=3.273268353539885, pvalue=0.016964736255752066)\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(a_accuracy_list), np.std(a_accuracy_list))\n",
    "print(np.mean(same_accuracy_list), np.std(same_accuracy_list))\n",
    "print(np.mean(b_accuracy_list), np.std(b_accuracy_list))\n",
    "\n",
    "print()\n",
    "\n",
    "print(ttest_ind(a_accuracy_list, same_accuracy_list))\n",
    "print(ttest_ind(a_accuracy_list, b_accuracy_list))\n",
    "print(ttest_ind(b_accuracy_list, same_accuracy_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is the model better at predicting any force class than humans?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166666666666666 0.14433756729740646\n",
      "0.5 0.16666666666666666\n",
      "1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "human_repel_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"resp_rel\", \n",
    "                                                                         \"true_rel\", \"'repel'\")\n",
    "\n",
    "human_none_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"resp_rel\", \n",
    "                                                                        \"true_rel\", \"'none'\")\n",
    "\n",
    "human_attract_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"resp_rel\", \n",
    "                                                                   \"true_rel\", \"'attract'\")\n",
    "\n",
    "print(np.mean(human_repel_accuracy_list), np.std(human_repel_accuracy_list))\n",
    "print(np.mean(human_none_accuracy_list), np.std(human_none_accuracy_list))\n",
    "print(np.mean(human_attract_accuracy_list), np.std(human_attract_accuracy_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_relResult(statistic=-2.4494897427831783, pvalue=0.09172111331157187)\n",
      "Ttest_relResult(statistic=2.6111648393354674, pvalue=0.07960498081790625)\n",
      "Ttest_relResult(statistic=-1.0, pvalue=0.39100221895577053)\n"
     ]
    }
   ],
   "source": [
    "print(ttest_rel(repel_accuracy_list, human_repel_accuracy_list))\n",
    "print(ttest_rel(none_accuracy_list, human_none_accuracy_list))\n",
    "print(ttest_rel(attract_accuracy_list, human_attract_accuracy_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is the model better at predicting any mass class than humans?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5833333333333334 0.14433756729740643\n",
      "0.08333333333333333 0.14433756729740646\n",
      "0.49999999999999994 0.37267799624996495\n",
      "\n"
     ]
    }
   ],
   "source": [
    "human_a_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"resp_mass\", \n",
    "                                                                     \"true_mass\", \"'A'\")\n",
    "\n",
    "human_same_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"resp_mass\", \n",
    "                                                                        \"true_mass\", \"'same'\")\n",
    "\n",
    "human_b_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"resp_mass\", \n",
    "                                                                     \"true_mass\", \"'B'\")\n",
    "\n",
    "print(np.mean(human_a_accuracy_list), np.std(human_a_accuracy_list))\n",
    "print(np.mean(human_same_accuracy_list), np.std(human_same_accuracy_list))\n",
    "print(np.mean(human_b_accuracy_list), np.std(human_b_accuracy_list))\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_relResult(statistic=-0.7745966692414834, pvalue=0.495025346059711)\n",
      "Ttest_relResult(statistic=2.449489742783178, pvalue=0.09172111331157187)\n",
      "Ttest_relResult(statistic=2.4494897427831783, pvalue=0.09172111331157187)\n"
     ]
    }
   ],
   "source": [
    "print(ttest_rel(a_accuracy_list, human_a_accuracy_list))\n",
    "print(ttest_rel(same_accuracy_list, human_same_accuracy_list))\n",
    "print(ttest_rel(b_accuracy_list, human_b_accuracy_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do model's correct answers correspond to examples that a higher percentage of humans guess?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mass responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=4.659555307287202, pvalue=0.03802985826378633)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_mass_correct_guesses = passive_responses.query(\"model_mass_correct_guesses\")[\"got_mass_right\"]\n",
    "post_mass_wrong_guesses = passive_responses.query(\"not model_mass_correct_guesses\")[\"got_mass_right\"]\n",
    "\n",
    "f_oneway(post_mass_correct_guesses, post_mass_wrong_guesses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 16)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(post_mass_correct_guesses), len(post_mass_wrong_guesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Force responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=1.1022776604149753, pvalue=0.3011724606372818)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_force_correct_guesses = passive_responses.query(\"model_force_correct_guesses\")['got_rel_right']\n",
    "post_force_wrong_guesses = passive_responses.query(\"not model_force_correct_guesses\")['got_rel_right']\n",
    "\n",
    "f_oneway(post_force_correct_guesses, post_force_wrong_guesses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 7)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(post_force_correct_guesses), len(post_force_wrong_guesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is the number of seeds getting a question correct correlated with the number of humans guessing it right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.45199166],\n",
       "       [0.45199166, 1.        ]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(passive_responses.models_got_mass_right, passive_responses.got_mass_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.00484687],\n",
       "       [0.00484687, 1.        ]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(passive_responses.models_got_rel_right, passive_responses.got_rel_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Are correct guesses / errors correlated to informativeness?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mass responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "not_na_passive_responses = passive_responses[passive_responses[\"post_ent\"].notna()]\n",
    "\n",
    "post_mass_correct_guesses = not_na_passive_responses.query(\"model_mass_correct_guesses\")[\"post_ent_mass.rtheta\"]\n",
    "post_mass_wrong_guesses = not_na_passive_responses.query(\"not model_mass_correct_guesses\")[\"post_ent_mass.rtheta\"]\n",
    "\n",
    "f_oneway(post_mass_correct_guesses, post_mass_wrong_guesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "post_mass_correct_guesses = not_na_passive_responses.query(\"corMass == 1\")[\"post_ent_mass.rtheta\"]\n",
    "post_mass_wrong_guesses = not_na_passive_responses.query(\"corMass == 0\")[\"post_ent_mass.rtheta\"]\n",
    "\n",
    "f_oneway(post_mass_correct_guesses, post_mass_wrong_guesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Force responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "post_force_correct_guesses = not_na_passive_responses[not_na_passive_responses.model_force_correct_guesses]['post_ent_rel.rtheta']\n",
    "post_force_wrong_guesses = not_na_passive_responses[~not_na_passive_responses.model_force_correct_guesses]['post_ent_rel.rtheta']\n",
    "\n",
    "f_oneway(post_force_correct_guesses, post_force_wrong_guesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "post_force_correct_guesses = not_na_passive_responses[(not_na_passive_responses.corRel).astype(bool)]['post_ent_rel.rtheta']\n",
    "post_force_wrong_guesses = not_na_passive_responses[~(not_na_passive_responses.corRel).astype(bool)]['post_ent_rel.rtheta']\n",
    "\n",
    "f_oneway(post_force_correct_guesses, post_force_wrong_guesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What percentage of the time does the model match the most common participant answer? second most common? and third?\n",
    "print((passive_responses[\"model_mass\"] == passive_responses[\"resp_mass\"]).sum() / len(passive_responses))\n",
    "print((passive_responses[\"model_mass\"] == passive_responses[\"second_resp_mass\"]).sum() / len(passive_responses))\n",
    "print((passive_responses[\"model_mass\"] == passive_responses[\"third_resp_mass\"]).sum() / len(passive_responses))\n",
    "print()\n",
    "print((passive_responses[\"model_relationship\"] == passive_responses[\"resp_rel\"]).sum() / len(passive_responses))\n",
    "print((passive_responses[\"model_relationship\"] == passive_responses[\"second_resp_rel\"]).sum() / len(passive_responses))\n",
    "print((passive_responses[\"model_relationship\"] == passive_responses[\"third_resp_rel\"]).sum() / len(passive_responses))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
