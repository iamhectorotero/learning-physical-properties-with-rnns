{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question to be answered:\n",
    "\n",
    "- Is the accuracy of model/human significantly better? In both force and mass questions?\n",
    "- Is the distribution of responses significantly different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import isaac.constants\n",
    "isaac.constants.TQDM_DISABLE = True\n",
    "\n",
    "from torch import nn\n",
    "from isaac.utils import get_cuda_device_if_available\n",
    "import joblib\n",
    "\n",
    "from isaac.dataset import read_dataset, prepare_dataset\n",
    "from isaac.models import MultiBranchModel\n",
    "from isaac.constants import BASIC_TRAINING_COLS, MASS_CLASS_COLS, FORCE_CLASS_COLS\n",
    "from isaac.evaluation import evaluate_saved_model\n",
    "from isaac.statistical_tests import z_test\n",
    "from isaac.visualization import plot_confusion_matrix\n",
    "\n",
    "from scipy.stats import ttest_ind, ttest_rel, f_oneway\n",
    "\n",
    "import torch\n",
    "import glob\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = get_cuda_device_if_available()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalise_data = True\n",
    "scaler_path = \"scalers_js/passive_dual_scaler.sk\"\n",
    "network_dims = (len(BASIC_TRAINING_COLS), 25, 3, 0.5)\n",
    "dataset_path = \"data/js_test_passive_trials.h5\"\n",
    "class_columns = [list(MASS_CLASS_COLS), list(FORCE_CLASS_COLS)]\n",
    "multiclass = True\n",
    "seq_end = 2700\n",
    "step_size = 3\n",
    "N_MODELS = 25\n",
    "TRIALS = read_dataset(dataset_path)\n",
    "\n",
    "def get_question_accuracy_for_group_of_models(question_type):    \n",
    "\n",
    "    model_paths = sorted(glob.glob(\"models/train_25_mb_with_js_data/best_\"+question_type+\"_model_seed_*.pt\"))\n",
    "    accuracies, predicted = evaluate_saved_model(tqdm(model_paths), network_dims, None, \n",
    "                                                 training_columns=BASIC_TRAINING_COLS, class_columns=class_columns, \n",
    "                                                 step_size=step_size, seq_end=seq_end, scaler_path=scaler_path,\n",
    "                                                 arch=MultiBranchModel, multiclass=multiclass, trials=TRIALS)\n",
    "    \n",
    "    \n",
    "    if question_type == \"mass\":\n",
    "        question_index = 0\n",
    "    else:\n",
    "        question_index = 1\n",
    "\n",
    "    accuracies = np.stack(accuracies)[:, question_index]\n",
    "    \n",
    "    predicted = [x[:, question_index].numpy() for x in predicted]\n",
    "\n",
    "    return accuracies, predicted\n",
    "\n",
    "def get_participant_accuracy_filtering_by_answer(passive_responses, answer_column, question_type_answer, filter_by_class):\n",
    "    \n",
    "    passive_responses = passive_responses.copy().query(question_type_answer+\" == \"+filter_by_class)\n",
    "    return passive_responses[answer_column]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T-test for MASS questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model's predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:49<00:00,  4.22s/it]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FORCE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:41<00:00,  3.97s/it]\n"
     ]
    }
   ],
   "source": [
    "print(\"MASS\")\n",
    "question_type = \"mass\"\n",
    "group_mass_acc, group_mass_prediction = get_question_accuracy_for_group_of_models(question_type)\n",
    "     \n",
    "print(\"\\nFORCE\")\n",
    "question_type = \"force\"\n",
    "group_force_acc, group_force_prediction = get_question_accuracy_for_group_of_models(question_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62.928000000000004, 2.893650981027256)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(group_mass_acc), np.std(group_mass_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(group_mass_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62.087999999999994, 3.4886467290340537)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(group_force_acc), np.std(group_force_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(69.7, 2), (68.0, 6), (66.5, 14), (65.2, 12), (65.1, 9)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(group_force_acc, range(len(group_force_acc))), key=lambda x: x[0], reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(68.7, 2), (66.6, 16), (65.6, 14), (65.4, 21), (65.3, 12)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(group_mass_acc, range(len(group_mass_acc))), key=lambda x: x[0], reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[2, 16, 14, 21, 12]\n",
    "[2, 6, 14, 12, 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is the model significantly better answering force questions than mass questions? And humans?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=0.9079120008416578, pvalue=0.36846059086537775)\n"
     ]
    }
   ],
   "source": [
    "print(ttest_ind(group_mass_acc, group_force_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from isaac.visualization import make_frame_curried\n",
    "import moviepy.editor as mpy\n",
    "\n",
    "def make_clip(trial_data):\n",
    "\n",
    "    duration = len(trial_data)\n",
    "\n",
    "    n_bodies = sum([\"o\"+str(i)+\".x\" in list(trial_data.columns) for i in range(1, 5)])\n",
    "    \n",
    "    while (len(trial_data) + 1) % 60 != 0:\n",
    "        trial_data = trial_data.append(trial_data.iloc[-1], ignore_index=True)\n",
    "    make_frame = make_frame_curried(trial_data, n_bodies)\n",
    "    clip = mpy.VideoClip(make_frame, duration=duration / 60)\n",
    "    return clip, trial_data\n",
    "\n",
    "clips = [make_clip(replay)[0] for replay in TRIALS[:25]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = clips[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "No 'fps' (frames per second) attribute specified for function write_videofile and the clip has no 'fps' attribute. Either provide e.g. fps=24 in the arguments of the function, or define the clip's fps with `clip.fps=24`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-f5c94bcb1477>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_videofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"here.mp4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m</home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/decorator.py:decorator-gen-175>\u001b[0m in \u001b[0;36mwrite_videofile\u001b[0;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, progress_bar)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/diss/lib/python3.5/site-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36mrequires_duration\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Attribute 'duration' not set\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/decorator.py:decorator-gen-174>\u001b[0m in \u001b[0;36mwrite_videofile\u001b[0;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, progress_bar)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/diss/lib/python3.5/site-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36muse_clip_fps_by_default\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     new_a = [fun(arg) if (name=='fps') else arg\n\u001b[0;32m--> 133\u001b[0;31m              for (arg, name) in zip(a, names)]\n\u001b[0m\u001b[1;32m    134\u001b[0m     new_kw = {k: fun(v) if k=='fps' else v\n\u001b[1;32m    135\u001b[0m              for (k,v) in k.items()}\n",
      "\u001b[0;32m~/miniconda3/envs/diss/lib/python3.5/site-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     new_a = [fun(arg) if (name=='fps') else arg\n\u001b[0;32m--> 133\u001b[0;31m              for (arg, name) in zip(a, names)]\n\u001b[0m\u001b[1;32m    134\u001b[0m     new_kw = {k: fun(v) if k=='fps' else v\n\u001b[1;32m    135\u001b[0m              for (k,v) in k.items()}\n",
      "\u001b[0;32m~/miniconda3/envs/diss/lib/python3.5/site-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36mfun\u001b[0;34m(fps)\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0;34m\" for function %s and the clip has no 'fps' attribute. Either\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;34m\" provide e.g. fps=24 in the arguments of the function, or define\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m                 \" the clip's fps with `clip.fps=24`\"%f.__name__)\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: No 'fps' (frames per second) attribute specified for function write_videofile and the clip has no 'fps' attribute. Either provide e.g. fps=24 in the arguments of the function, or define the clip's fps with `clip.fps=24`"
     ]
    }
   ],
   "source": [
    "a.write_videofile(\"here.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
