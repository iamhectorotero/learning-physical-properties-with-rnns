{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question to be answered:\n",
    "\n",
    "- Is the accuracy of model/human significantly better? In both force and mass questions?\n",
    "- Is the distribution of responses significantly different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import isaac.constants\n",
    "isaac.constants.TQDM_DISABLE = True\n",
    "\n",
    "from torch import nn\n",
    "from isaac.utils import get_cuda_device_if_available\n",
    "import joblib\n",
    "\n",
    "from isaac.dataset import read_dataset, prepare_dataset\n",
    "from isaac.models import MultiBranchModel\n",
    "from isaac.constants import BASIC_TRAINING_COLS, MASS_CLASS_COLS, FORCE_CLASS_COLS\n",
    "from isaac.evaluation import evaluate_saved_model\n",
    "from isaac.statistical_tests import z_test\n",
    "\n",
    "import torch\n",
    "import glob\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = get_cuda_device_if_available()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_question_accuracy_for_group_of_models(question_type):\n",
    "    normalise_data = True\n",
    "    scaler_path = \"scalers/passive_dual_scaler.sk\"\n",
    "    network_dims = (len(BASIC_TRAINING_COLS), 25, 3, 0.5)\n",
    "    dataset_path = \"data/passive_trials_exp1.h5\"\n",
    "    class_columns = [list(MASS_CLASS_COLS), list(FORCE_CLASS_COLS)]\n",
    "    multiclass = True\n",
    "    seq_end = 1800\n",
    "    step_size = 3\n",
    "    \n",
    "    models = sorted(glob.glob(\"models/best_\"+question_type+\"_model_seed_*.pt\"))\n",
    "\n",
    "    group_accuracy = []\n",
    "    group_predictions = []\n",
    "\n",
    "    for model_path in tqdm(models):\n",
    "        accuracies, predicted = evaluate_saved_model(model_path, network_dims, dataset_path, \n",
    "                                                     training_columns=BASIC_TRAINING_COLS, class_columns=class_columns, \n",
    "                                                     step_size=step_size, seq_end=seq_end, scaler_path=scaler_path,\n",
    "                                                     arch=MultiBranchModel, multiclass=multiclass)\n",
    "\n",
    "        if question_type == \"mass\":\n",
    "            accuracy = accuracies[0]\n",
    "            predicted = predicted[:, 0]\n",
    "        else:\n",
    "            accuracy = accuracies[1]\n",
    "            predicted = predicted[:, 1]\n",
    "\n",
    "        group_accuracy.append(accuracy)\n",
    "        group_predictions.append(predicted.numpy())\n",
    "\n",
    "    return group_accuracy, group_predictions\n",
    "\n",
    "def get_participant_accuracy(passive_responses, answer_column, question_type_answer):\n",
    "    return [(df[answer_column] == df[question_type_answer]).sum() / len(df) \n",
    "            for participant_id, df in passive_responses.groupby(\"participant\")]\n",
    "\n",
    "\n",
    "def get_participant_accuracy_filtering_by_answer(passive_responses, answer_column, question_type_answer, filter_by_class):\n",
    "    \n",
    "    passive_responses = passive_responses.copy().query(question_type_answer+\" == \"+filter_by_class)\n",
    "    \n",
    "    return [(df[answer_column] == df[question_type_answer]).sum() / len(df) \n",
    "            for participant_id, df in passive_responses.groupby(\"participant\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T-test for MASS questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model's predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:03<00:12,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [54.16666667 56.94444444]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 2/5 [00:05<00:08,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [56.01851852 52.77777778]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 3/5 [00:07<00:05,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [53.7037037  58.33333333]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 4/5 [00:10<00:02,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [54.62962963 56.94444444]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:12<00:00,  2.60s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [58.7962963  60.64814815]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 1/5 [00:02<00:09,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [59.72222222 61.57407407]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 2/5 [00:04<00:07,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [50.46296296 52.77777778]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 3/5 [00:07<00:04,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [53.7037037  59.25925926]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 4/5 [00:09<00:02,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [53.24074074 62.03703704]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 5/5 [00:12<00:00,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [54.62962963 62.5       ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "question_type = \"mass\"\n",
    "group_mass_acc, group_mass_prediction = get_question_accuracy_for_group_of_models(question_type)\n",
    "     \n",
    "question_type = \"force\"\n",
    "group_force_acc, group_force_prediction = get_question_accuracy_for_group_of_models(question_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55.462962962962955, 59.62962962962963)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(group_mass_acc), np.mean(group_force_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "\n",
    "group_mass_prediction = np.array(group_mass_prediction)\n",
    "group_force_prediction = np.array(group_force_prediction)\n",
    "\n",
    "majority_mass_predictions, _ = mode(group_mass_prediction, axis=0)\n",
    "majority_force_predictions, _ = mode(group_force_prediction, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_mass_answers = [MASS_CLASS_COLS[i] for i in majority_mass_predictions[0]]\n",
    "ensemble_force_answers = [FORCE_CLASS_COLS[i] for i in majority_force_predictions[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load human results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning: Warning messages:\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning: 1: \n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning: In value[[3L]](cond) :\n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning: \n",
      " \n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning:  \"getThreads\" not available for .C() for package \"RevoUtilsMath\"\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning: 2: \n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning: 3: \n",
      "  warnings.warn(x, RRuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from rpy2.robjects import r, pandas2ri\n",
    "pandas2ri.activate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/rpy2/robjects/pandas2ri.py:191: FutureWarning: from_items is deprecated. Please use DataFrame.from_dict(dict(items), ...) instead. DataFrame.from_dict(OrderedDict(items)) may be used to preserve the key order.\n",
      "  res = PandasDataFrame.from_items(items)\n"
     ]
    }
   ],
   "source": [
    "rdata_path = \"for_hector_small/data/exp1.rdata\"\n",
    "r['load'](rdata_path)\n",
    "\n",
    "is_passive = (r['dfc.l'].condition == '0') & (r['dfc.l'].practice == 0.) & (r['dfc.l'].exclude == 0)\n",
    "responses = r['dfc.l'][[\"participant\", \"mass\", \"relationship\", \"trueMass\", \"trueRelationship\", 'post_ent', 'post_ent_rel.rtheta', 'post_ent_mass.rtheta', 'corMass', 'corRel']]\n",
    "passive_responses = responses[is_passive]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "passive_responses[\"model_mass\"] = ensemble_mass_answers\n",
    "passive_responses[\"model_relationship\"] = ensemble_force_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_mass_accuracy_list = get_participant_accuracy(passive_responses, \"mass\", \"trueMass\")\n",
    "human_force_accuracy_list = get_participant_accuracy(passive_responses, \"relationship\", \"trueRelationship\")\n",
    "\n",
    "model_mass_accuracy_list = get_participant_accuracy(passive_responses, \"model_mass\", \"trueMass\")\n",
    "model_force_accuracy_list = get_participant_accuracy(passive_responses, \"model_relationship\", \"trueRelationship\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4537037037037037 ± 0.1922272175187657\n",
      "0.5787037037037037 ± 0.16348558873157015\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(human_mass_accuracy_list), \"±\", np.std(human_mass_accuracy_list))\n",
    "print(np.mean(model_mass_accuracy_list), \"±\", np.std(model_mass_accuracy_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6574074074074073 ± 0.16640926625566138\n",
      "0.611111111111111 ± 0.2151657414559676\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(model_force_accuracy_list), \"±\", np.std(model_force_accuracy_list))\n",
    "print(np.mean(human_force_accuracy_list), \"±\", np.std(human_force_accuracy_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform t-test on overall accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null hypothesis (opposite of what we want to prove): accuracies are not significantly different\n",
    "# Alternative hypothesis: accuracies are significantly different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind, ttest_rel, f_oneway"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is the model significantly better answering mass questions than humans?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=-2.3305550584499115, pvalue=0.028907500943665062)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_rel(human_mass_accuracy_list, model_mass_accuracy_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is the model significantly better answering force questions than humans?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=-0.7382572022557348, pvalue=0.4678248501407801)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_rel(human_force_accuracy_list, model_force_accuracy_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is the model significantly better answering force questions than mass questions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-1.6180110712548972, pvalue=0.11249773981293777)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_ind(model_mass_accuracy_list, model_force_accuracy_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform z-test on overall accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null hypothesis (opposite of what we want to prove): accuracies are not significantly different\n",
    "# Alternative hypothesis: classifier 2 is significantly more accurate than the first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "z_zero_point_five = 1.645"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z = z_test(passive_responses[\"trueMass\"], passive_responses[\"mass\"], passive_responses[\"model_mass\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(Z)\n",
    "if Z < -z_zero_point_five:\n",
    "    print(\"Classifier two significantly better than classifier one.\")\n",
    "else:\n",
    "    print(\"Classifier two not significantly better.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z = z_test(passive_responses[\"trueRelationship\"], passive_responses[\"relationship\"], passive_responses[\"model_relationship\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(Z)\n",
    "if Z < -z_zero_point_five:\n",
    "    print(\"Classifier two significantly better than classifier one.\")\n",
    "else:\n",
    "    print(\"Classifier two not significantly better than classifier one.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Are correct guesses / errors correlated between humans and model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chisquare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "passive_responses[\"model_mass_correct_guesses\"] = (passive_responses[\"model_mass\"] == passive_responses[\"trueMass\"])\n",
    "passive_responses[\"model_force_correct_guesses\"] = (passive_responses[\"model_relationship\"] == passive_responses[\"trueRelationship\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4537037037037037 0.15354744399793518\n",
      "0.46759259259259256 0.15375668430940384\n"
     ]
    }
   ],
   "source": [
    "mass_coincidence = get_participant_accuracy(passive_responses, \"mass\", \"model_mass\")\n",
    "force_coincidence = get_participant_accuracy(passive_responses, \"relationship\", \"model_relationship\")\n",
    "\n",
    "print(np.mean(mass_coincidence), np.std(mass_coincidence))\n",
    "print(np.mean(force_coincidence), np.std(force_coincidence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_for_independence(first_answers, second_answers):\n",
    "    both_correct = (first_answers & second_answers).sum()\n",
    "    both_wrong = (~first_answers & ~second_answers).sum()\n",
    "    first_correct_second_wrong = (~first_answers & second_answers).sum()\n",
    "    first_wrong_second_correct = (first_answers & ~second_answers).sum()\n",
    "    \n",
    "    matrix = [[both_correct, first_correct_second_wrong], [first_wrong_second_correct, both_wrong]]\n",
    "    chisquare_results = chisquare(matrix, axis=None)\n",
    "    \n",
    "    return matrix, chisquare_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[83, 59], [49, 25]],\n",
       " Power_divergenceResult(statistic=32.074074074074076, pvalue=5.0486794044425e-07))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_for_independence(passive_responses[\"corRel\"], passive_responses[\"model_force_correct_guesses\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[59, 66], [39, 52]],\n",
       " Power_divergenceResult(statistic=7.37037037037037, pvalue=0.06098442930559373))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_for_independence(passive_responses[\"corMass\"], passive_responses[\"model_mass_correct_guesses\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_for_coincidence(first_answers, second_answers):\n",
    "    \n",
    "    matrix = []\n",
    "    all_classes = first_answers.unique()\n",
    "    \n",
    "    for class_name in all_classes:\n",
    "        this_class_coincidences = []\n",
    "        for second_class_name in all_classes:\n",
    "            n_coincidences = ((first_answers == class_name) & (second_answers == second_class_name)).sum()\n",
    "            this_class_coincidences.append(n_coincidences)\n",
    "            \n",
    "        matrix.append(this_class_coincidences)\n",
    "    \n",
    "    chisquare_results = chisquare(matrix, axis=None)\n",
    "    \n",
    "    return matrix, chisquare_results, all_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[17, 19, 33], [18, 39, 15], [12, 21, 42]],\n",
       " Power_divergenceResult(statistic=40.58333333333333, pvalue=2.493864075123097e-06),\n",
       " array(['same', 'B', 'A'], dtype=object))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_for_coincidence(passive_responses[\"mass\"], passive_responses[\"model_mass\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[24, 29, 9], [8, 49, 38], [3, 28, 28]],\n",
       " Power_divergenceResult(statistic=75.0, pvalue=4.932659739935825e-13),\n",
       " array(['attract', 'none', 'repel'], dtype=object))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_for_coincidence(passive_responses[\"relationship\"], passive_responses[\"model_relationship\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Are correct guesses / errors correlated to informativeness?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mass responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=1.5323649072780126, pvalue=0.21757124338259207)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_na_passive_responses = passive_responses[passive_responses[\"post_ent\"].notna()]\n",
    "\n",
    "post_mass_correct_guesses = not_na_passive_responses.query(\"model_mass_correct_guesses\")[\"post_ent_mass.rtheta\"]\n",
    "post_mass_wrong_guesses = not_na_passive_responses.query(\"not model_mass_correct_guesses\")[\"post_ent_mass.rtheta\"]\n",
    "\n",
    "f_oneway(post_mass_correct_guesses, post_mass_wrong_guesses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=0.03857733827167141, pvalue=0.8445376237361524)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_mass_correct_guesses = not_na_passive_responses.query(\"corMass == 1\")[\"post_ent_mass.rtheta\"]\n",
    "post_mass_wrong_guesses = not_na_passive_responses.query(\"corMass == 0\")[\"post_ent_mass.rtheta\"]\n",
    "\n",
    "f_oneway(post_mass_correct_guesses, post_mass_wrong_guesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Force responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=3.3989831343693866, pvalue=0.06708642765414946)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_force_correct_guesses = not_na_passive_responses[not_na_passive_responses.model_force_correct_guesses]['post_ent_rel.rtheta']\n",
    "post_force_wrong_guesses = not_na_passive_responses[~not_na_passive_responses.model_force_correct_guesses]['post_ent_rel.rtheta']\n",
    "\n",
    "f_oneway(post_force_correct_guesses, post_force_wrong_guesses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=5.982515021800705, pvalue=0.015531865919044263)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_force_correct_guesses = not_na_passive_responses[(not_na_passive_responses.corRel).astype(bool)]['post_ent_rel.rtheta']\n",
    "post_force_wrong_guesses = not_na_passive_responses[~(not_na_passive_responses.corRel).astype(bool)]['post_ent_rel.rtheta']\n",
    "\n",
    "f_oneway(post_force_correct_guesses, post_force_wrong_guesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Same statistic calculated a different way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_copy = not_na_passive_responses.copy()\n",
    "df_copy = df_copy.rename({'post_ent_rel.rtheta': 'post_ent_rel_rtheta',\n",
    "                          'post_ent_mass.rtheta': 'post_ent_mass_rtheta'}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "moore_lm = ols('post_ent_mass_rtheta ~ corMass', data=df_copy).fit()\n",
    "table = sm.stats.anova_lm(moore_lm, typ=2)\n",
    "print(table)\n",
    "\n",
    "moore_lm = ols('post_ent_rel_rtheta ~ corRel', data=df_copy).fit()\n",
    "table = sm.stats.anova_lm(moore_lm, typ=2)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is the model better at predicting any force class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "repel_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"model_relationship\", \n",
    "                                                                   \"trueRelationship\", \"'repel'\")\n",
    "\n",
    "none_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"model_relationship\", \n",
    "                                                                   \"trueRelationship\", \"'none'\")\n",
    "\n",
    "attract_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"model_relationship\", \n",
    "                                                                   \"trueRelationship\", \"'attract'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.625 0.2602082499332666\n",
      "0.6875 0.2724311839712921\n",
      "0.6458333333333334 0.3673998351780916\n",
      "\n",
      "Ttest_indResult(statistic=-0.795630267734819, pvalue=0.4303336272798818)\n",
      "Ttest_indResult(statistic=-0.22192461632704463, pvalue=0.8253548952953591)\n",
      "Ttest_indResult(statistic=-0.4368882801067173, pvalue=0.664236448528826)\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(repel_accuracy_list), np.std(repel_accuracy_list))\n",
    "print(np.mean(none_accuracy_list), np.std(none_accuracy_list))\n",
    "print(np.mean(attract_accuracy_list), np.std(attract_accuracy_list))\n",
    "\n",
    "print()\n",
    "\n",
    "print(ttest_ind(repel_accuracy_list, none_accuracy_list))\n",
    "print(ttest_ind(repel_accuracy_list, attract_accuracy_list))\n",
    "print(ttest_ind(attract_accuracy_list, none_accuracy_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is the model better at predicting any mass class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"model_mass\", \n",
    "                                                                   \"trueMass\", \"'A'\")\n",
    "\n",
    "same_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"model_mass\", \n",
    "                                                                   \"trueMass\", \"'same'\")\n",
    "\n",
    "b_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"model_mass\", \n",
    "                                                                   \"trueMass\", \"'B'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7222222222222222 0.2664350846284844\n",
      "0.375 0.24176243313235013\n",
      "0.6388888888888888 0.23405971592156552\n",
      "\n",
      "Ttest_indResult(statistic=4.6285255624513155, pvalue=3.0219150546836055e-05)\n",
      "Ttest_indResult(statistic=1.126915547104906, pvalue=0.26562258203569544)\n",
      "Ttest_indResult(statistic=3.76095786849388, pvalue=0.00047715292903339075)\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(a_accuracy_list), np.std(a_accuracy_list))\n",
    "print(np.mean(same_accuracy_list), np.std(same_accuracy_list))\n",
    "print(np.mean(b_accuracy_list), np.std(b_accuracy_list))\n",
    "\n",
    "print()\n",
    "\n",
    "print(ttest_ind(a_accuracy_list, same_accuracy_list))\n",
    "print(ttest_ind(a_accuracy_list, b_accuracy_list))\n",
    "print(ttest_ind(b_accuracy_list, same_accuracy_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is the model better at predicting any force class than humans?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5277777777777778 0.3458305443885759\n",
      "0.6041666666666666 0.25937290829143195\n",
      "0.75 0.3227486121839514\n"
     ]
    }
   ],
   "source": [
    "human_repel_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"relationship\", \n",
    "                                                                         \"trueRelationship\", \"'repel'\")\n",
    "\n",
    "human_none_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"relationship\", \n",
    "                                                                        \"trueRelationship\", \"'none'\")\n",
    "\n",
    "human_attract_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"relationship\", \n",
    "                                                                   \"trueRelationship\", \"'attract'\")\n",
    "\n",
    "print(np.mean(human_repel_accuracy_list), np.std(human_repel_accuracy_list))\n",
    "print(np.mean(human_none_accuracy_list), np.std(human_none_accuracy_list))\n",
    "print(np.mean(human_attract_accuracy_list), np.std(human_attract_accuracy_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_relResult(statistic=1.0707428896364521, pvalue=0.29539313735467326)\n",
      "Ttest_relResult(statistic=0.9405399431259601, pvalue=0.3567147403555685)\n",
      "Ttest_relResult(statistic=-0.9607046637980575, pvalue=0.34669239711665734)\n"
     ]
    }
   ],
   "source": [
    "print(ttest_rel(repel_accuracy_list, human_repel_accuracy_list))\n",
    "print(ttest_rel(none_accuracy_list, human_none_accuracy_list))\n",
    "print(ttest_rel(attract_accuracy_list, human_attract_accuracy_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is the model better at predicting any mass class than humans?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 0.2545875386086578\n",
      "0.375 0.3236438943814179\n",
      "0.4861111111111111 0.33304385578560547\n",
      "\n"
     ]
    }
   ],
   "source": [
    "human_a_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"mass\", \n",
    "                                                                     \"trueMass\", \"'A'\")\n",
    "\n",
    "human_same_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"mass\", \n",
    "                                                                        \"trueMass\", \"'same'\")\n",
    "\n",
    "human_b_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"mass\", \n",
    "                                                                     \"trueMass\", \"'B'\")\n",
    "\n",
    "print(np.mean(human_a_accuracy_list), np.std(human_a_accuracy_list))\n",
    "print(np.mean(human_same_accuracy_list), np.std(human_same_accuracy_list))\n",
    "print(np.mean(human_b_accuracy_list), np.std(human_b_accuracy_list))\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_relResult(statistic=2.5634797778466227, pvalue=0.017370026723767275)\n",
      "Ttest_relResult(statistic=-1.118356635373715e-16, pvalue=0.9999999999999999)\n",
      "Ttest_relResult(statistic=1.9048418372748412, pvalue=0.06938047123922489)\n"
     ]
    }
   ],
   "source": [
    "print(ttest_rel(a_accuracy_list, human_a_accuracy_list))\n",
    "print(ttest_rel(same_accuracy_list, human_same_accuracy_list))\n",
    "print(ttest_rel(b_accuracy_list, human_b_accuracy_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
