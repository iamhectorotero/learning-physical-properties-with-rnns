{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question to be answered:\n",
    "\n",
    "- Is the accuracy of model/human significantly better? In both force and mass questions?\n",
    "- Is the distribution of responses significantly different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import isaac.constants\n",
    "isaac.constants.TQDM_DISABLE = True\n",
    "\n",
    "from torch import nn\n",
    "from isaac.utils import get_cuda_device_if_available\n",
    "import joblib\n",
    "\n",
    "from isaac.dataset import read_dataset, prepare_dataset\n",
    "from isaac.models import MultiBranchModel\n",
    "from isaac.constants import BASIC_TRAINING_COLS, MASS_CLASS_COLS, FORCE_CLASS_COLS\n",
    "from isaac.evaluation import evaluate_saved_model\n",
    "from isaac.statistical_tests import z_test\n",
    "\n",
    "import torch\n",
    "import glob\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = get_cuda_device_if_available()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_question_accuracy_for_group_of_models(question_type):\n",
    "    normalise_data = True\n",
    "    scaler_path = \"scalers/passive_dual_scaler.sk\"\n",
    "    network_dims = (len(BASIC_TRAINING_COLS), 25, 3, 0.5)\n",
    "    dataset_path = \"data/passive_trials_exp1.h5\"\n",
    "    class_columns = [list(MASS_CLASS_COLS), list(FORCE_CLASS_COLS)]\n",
    "    multiclass = True\n",
    "    seq_end = 1800\n",
    "    step_size = 3\n",
    "    \n",
    "    models = sorted(glob.glob(\"models/best_\"+question_type+\"_model_seed_*.pt\"))\n",
    "\n",
    "    group_accuracy = []\n",
    "    group_predictions = []\n",
    "\n",
    "    for model_path in tqdm(models):\n",
    "        accuracies, predicted = evaluate_saved_model(model_path, network_dims, dataset_path, \n",
    "                                                     training_columns=BASIC_TRAINING_COLS, class_columns=class_columns, \n",
    "                                                     step_size=step_size, seq_end=seq_end, scaler_path=scaler_path,\n",
    "                                                     arch=MultiBranchModel, multiclass=multiclass)\n",
    "\n",
    "        if question_type == \"mass\":\n",
    "            accuracy = accuracies[0]\n",
    "            predicted = predicted[:, 0]\n",
    "        else:\n",
    "            accuracy = accuracies[1]\n",
    "            predicted = predicted[:, 1]\n",
    "\n",
    "        group_accuracy.append(accuracy)\n",
    "        group_predictions.append(predicted.numpy())\n",
    "\n",
    "    return group_accuracy, group_predictions\n",
    "\n",
    "def get_participant_accuracy(passive_responses, answer_column, question_type_answer):\n",
    "    return [(df[answer_column] == df[question_type_answer]).sum() / len(df) \n",
    "            for participant_id, df in passive_responses.groupby(\"participant\")]\n",
    "\n",
    "\n",
    "def get_participant_accuracy_filtering_by_answer(passive_responses, answer_column, question_type_answer, filter_by_class):\n",
    "    \n",
    "    passive_responses = passive_responses.copy().query(question_type_answer+\" == \"+filter_by_class)\n",
    "    \n",
    "    return [(df[answer_column] == df[question_type_answer]).sum() / len(df) \n",
    "            for participant_id, df in passive_responses.groupby(\"participant\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T-test for MASS questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model's predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:03<00:12,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [31.01851852 36.11111111]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 2/5 [00:05<00:08,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [32.87037037 44.44444444]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 3/5 [00:08<00:05,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [27.77777778 22.22222222]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 4/5 [00:10<00:02,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [32.40740741 39.35185185]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:13<00:00,  2.63s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [33.33333333 43.51851852]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 1/5 [00:02<00:10,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [31.01851852 36.11111111]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 2/5 [00:04<00:07,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [32.87037037 44.44444444]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 3/5 [00:07<00:04,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [29.16666667 34.25925926]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 4/5 [00:09<00:02,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [32.40740741 39.35185185]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 5/5 [00:12<00:00,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [33.33333333 43.51851852]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "question_type = \"mass\"\n",
    "group_mass_acc, group_mass_prediction = get_question_accuracy_for_group_of_models(question_type)\n",
    "     \n",
    "question_type = \"force\"\n",
    "group_force_acc, group_force_prediction = get_question_accuracy_for_group_of_models(question_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31.481481481481485, 39.53703703703703)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(group_mass_acc), np.mean(group_force_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "\n",
    "group_mass_prediction = np.array(group_mass_prediction)\n",
    "group_force_prediction = np.array(group_force_prediction)\n",
    "\n",
    "majority_mass_predictions, _ = mode(group_mass_prediction, axis=0)\n",
    "majority_force_predictions, _ = mode(group_force_prediction, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_mass_answers = [MASS_CLASS_COLS[i] for i in majority_mass_predictions[0]]\n",
    "ensemble_force_answers = [FORCE_CLASS_COLS[i] for i in majority_force_predictions[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load human results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning: Warning messages:\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning: 1: \n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning: In value[[3L]](cond) :\n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning: \n",
      " \n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning:  \"getThreads\" not available for .C() for package \"RevoUtilsMath\"\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning: 2: \n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning: 3: \n",
      "  warnings.warn(x, RRuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from rpy2.robjects import r, pandas2ri\n",
    "pandas2ri.activate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/rpy2/robjects/pandas2ri.py:191: FutureWarning: from_items is deprecated. Please use DataFrame.from_dict(dict(items), ...) instead. DataFrame.from_dict(OrderedDict(items)) may be used to preserve the key order.\n",
      "  res = PandasDataFrame.from_items(items)\n"
     ]
    }
   ],
   "source": [
    "rdata_path = \"for_hector_small/data/exp1.rdata\"\n",
    "r['load'](rdata_path)\n",
    "\n",
    "is_passive = (r['dfc.l'].condition == '0') & (r['dfc.l'].practice == 0.) & (r['dfc.l'].exclude == 0)\n",
    "responses = r['dfc.l'][[\"participant\", \"mass\", \"relationship\", \"trueMass\", \"trueRelationship\", 'post_ent', 'post_ent_rel.rtheta', 'post_ent_mass.rtheta', 'corMass', 'corRel']]\n",
    "passive_responses = responses[is_passive]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "passive_responses[\"model_mass\"] = ensemble_mass_answers\n",
    "passive_responses[\"model_relationship\"] = ensemble_force_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_mass_accuracy_list = get_participant_accuracy(passive_responses, \"mass\", \"trueMass\")\n",
    "human_force_accuracy_list = get_participant_accuracy(passive_responses, \"relationship\", \"trueRelationship\")\n",
    "\n",
    "model_mass_accuracy_list = get_participant_accuracy(passive_responses, \"model_mass\", \"trueMass\")\n",
    "model_force_accuracy_list = get_participant_accuracy(passive_responses, \"model_relationship\", \"trueRelationship\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4537037037037037 ± 0.1922272175187657\n",
      "0.3287037037037037 ± 0.02220292371904037\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(human_mass_accuracy_list), \"±\", np.std(human_mass_accuracy_list))\n",
    "print(np.mean(model_mass_accuracy_list), \"±\", np.std(model_mass_accuracy_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4166666666666667 ± 0.05782405554072591\n",
      "0.611111111111111 ± 0.2151657414559676\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(model_force_accuracy_list), \"±\", np.std(model_force_accuracy_list))\n",
    "print(np.mean(human_force_accuracy_list), \"±\", np.std(human_force_accuracy_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform t-test on overall accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null hypothesis (opposite of what we want to prove): accuracies are not significantly different\n",
    "# Alternative hypothesis: accuracies are significantly different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind, ttest_rel, f_oneway"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is the model significantly better answering mass questions than humans?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=3.1906626065525105, pvalue=0.0040684049186777696)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_rel(human_mass_accuracy_list, model_mass_accuracy_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is the model significantly better answering force questions than humans?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=3.7455367630225616, pvalue=0.0010559813084842161)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_rel(human_force_accuracy_list, model_force_accuracy_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is the model significantly better answering force questions than mass questions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-6.810688280954811, pvalue=1.7530289028889897e-08)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_ind(model_mass_accuracy_list, model_force_accuracy_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform z-test on overall accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null hypothesis (opposite of what we want to prove): accuracies are not significantly different\n",
    "# Alternative hypothesis: classifier 2 is significantly more accurate than the first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "z_zero_point_five = 1.645"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z = z_test(passive_responses[\"trueMass\"], passive_responses[\"mass\"], passive_responses[\"model_mass\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(Z)\n",
    "if Z < -z_zero_point_five:\n",
    "    print(\"Classifier two significantly better than classifier one.\")\n",
    "else:\n",
    "    print(\"Classifier two not significantly better.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z = z_test(passive_responses[\"trueRelationship\"], passive_responses[\"relationship\"], passive_responses[\"model_relationship\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(Z)\n",
    "if Z < -z_zero_point_five:\n",
    "    print(\"Classifier two significantly better than classifier one.\")\n",
    "else:\n",
    "    print(\"Classifier two not significantly better than classifier one.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Are correct guesses / errors correlated between humans and model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chisquare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "passive_responses[\"model_mass_correct_guesses\"] = (passive_responses[\"model_mass\"] == passive_responses[\"trueMass\"])\n",
    "passive_responses[\"model_force_correct_guesses\"] = (passive_responses[\"model_relationship\"] == passive_responses[\"trueRelationship\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34259259259259256 0.14669425479402648\n",
      "0.40277777777777785 0.1353721436779023\n"
     ]
    }
   ],
   "source": [
    "mass_coincidence = get_participant_accuracy(passive_responses, \"mass\", \"model_mass\")\n",
    "force_coincidence = get_participant_accuracy(passive_responses, \"relationship\", \"model_relationship\")\n",
    "\n",
    "print(np.mean(mass_coincidence), np.std(mass_coincidence))\n",
    "print(np.mean(force_coincidence), np.std(force_coincidence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_for_independence(first_answers, second_answers):\n",
    "    both_correct = (first_answers & second_answers).sum()\n",
    "    both_wrong = (~first_answers & ~second_answers).sum()\n",
    "    first_correct_second_wrong = (~first_answers & second_answers).sum()\n",
    "    first_wrong_second_correct = (first_answers & ~second_answers).sum()\n",
    "    \n",
    "    matrix = [[both_correct, first_correct_second_wrong], [first_wrong_second_correct, both_wrong]]\n",
    "    chisquare_results = chisquare(matrix, axis=None)\n",
    "    \n",
    "    return matrix, chisquare_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[51, 39], [81, 45]],\n",
       " Power_divergenceResult(statistic=19.333333333333336, pvalue=0.00023326399901124658))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_for_independence(passive_responses[\"corRel\"], passive_responses[\"model_force_correct_guesses\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[35, 36], [63, 82]],\n",
       " Power_divergenceResult(statistic=28.703703703703702, pvalue=2.5845665408193226e-06))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_for_independence(passive_responses[\"corMass\"], passive_responses[\"model_mass_correct_guesses\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_for_coincidence(first_answers, second_answers):\n",
    "    \n",
    "    matrix = []\n",
    "    all_classes = first_answers.unique()\n",
    "    \n",
    "    for class_name in all_classes:\n",
    "        this_class_coincidences = []\n",
    "        for second_class_name in all_classes:\n",
    "            n_coincidences = ((first_answers == class_name) & (second_answers == second_class_name)).sum()\n",
    "            this_class_coincidences.append(n_coincidences)\n",
    "            \n",
    "        matrix.append(this_class_coincidences)\n",
    "    \n",
    "    chisquare_results = chisquare(matrix, axis=None)\n",
    "    \n",
    "    return matrix, chisquare_results, all_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[0, 0, 69], [0, 0, 72], [0, 1, 74]],\n",
       " Power_divergenceResult(statistic=426.58333333333337, pvalue=3.8326502365740223e-87),\n",
       " array(['same', 'B', 'A'], dtype=object))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_for_coincidence(passive_responses[\"mass\"], passive_responses[\"model_mass\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[2, 60, 0], [10, 85, 0], [2, 57, 0]],\n",
       " Power_divergenceResult(statistic=374.91666666666663, pvalue=4.3192848529991275e-76),\n",
       " array(['attract', 'none', 'repel'], dtype=object))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_for_coincidence(passive_responses[\"relationship\"], passive_responses[\"model_relationship\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Are correct guesses / errors correlated to informativeness?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mass responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=4.297642802150152, pvalue=0.03976847389477966)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_na_passive_responses = passive_responses[passive_responses[\"post_ent\"].notna()]\n",
    "\n",
    "post_mass_correct_guesses = not_na_passive_responses.query(\"model_mass_correct_guesses\")[\"post_ent_mass.rtheta\"]\n",
    "post_mass_wrong_guesses = not_na_passive_responses.query(\"not model_mass_correct_guesses\")[\"post_ent_mass.rtheta\"]\n",
    "\n",
    "f_oneway(post_mass_correct_guesses, post_mass_wrong_guesses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=0.03857733827167141, pvalue=0.8445376237361524)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_mass_correct_guesses = not_na_passive_responses.query(\"corMass == 1\")[\"post_ent_mass.rtheta\"]\n",
    "post_mass_wrong_guesses = not_na_passive_responses.query(\"corMass == 0\")[\"post_ent_mass.rtheta\"]\n",
    "\n",
    "f_oneway(post_mass_correct_guesses, post_mass_wrong_guesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Force responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=0.02512060144015596, pvalue=0.8742667881234977)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_force_correct_guesses = not_na_passive_responses[not_na_passive_responses.model_force_correct_guesses]['post_ent_rel.rtheta']\n",
    "post_force_wrong_guesses = not_na_passive_responses[~not_na_passive_responses.model_force_correct_guesses]['post_ent_rel.rtheta']\n",
    "\n",
    "f_oneway(post_force_correct_guesses, post_force_wrong_guesses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=5.982515021800705, pvalue=0.015531865919044263)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_force_correct_guesses = not_na_passive_responses[(not_na_passive_responses.corRel).astype(bool)]['post_ent_rel.rtheta']\n",
    "post_force_wrong_guesses = not_na_passive_responses[~(not_na_passive_responses.corRel).astype(bool)]['post_ent_rel.rtheta']\n",
    "\n",
    "f_oneway(post_force_correct_guesses, post_force_wrong_guesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Same statistic calculated a different way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_copy = not_na_passive_responses.copy()\n",
    "df_copy = df_copy.rename({'post_ent_rel.rtheta': 'post_ent_rel_rtheta',\n",
    "                          'post_ent_mass.rtheta': 'post_ent_mass_rtheta'}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "moore_lm = ols('post_ent_mass_rtheta ~ corMass', data=df_copy).fit()\n",
    "table = sm.stats.anova_lm(moore_lm, typ=2)\n",
    "print(table)\n",
    "\n",
    "moore_lm = ols('post_ent_rel_rtheta ~ corRel', data=df_copy).fit()\n",
    "table = sm.stats.anova_lm(moore_lm, typ=2)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is the model better at predicting any force class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "repel_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"model_relationship\", \n",
    "                                                                   \"trueRelationship\", \"'repel'\")\n",
    "\n",
    "none_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"model_relationship\", \n",
    "                                                                   \"trueRelationship\", \"'none'\")\n",
    "\n",
    "attract_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"model_relationship\", \n",
    "                                                                   \"trueRelationship\", \"'attract'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0\n",
      "0.90625 0.14091405477571545\n",
      "0.0625 0.16535945694153692\n",
      "\n",
      "Ttest_indResult(statistic=-30.843071863340935, pvalue=2.2310244708265363e-32)\n",
      "Ttest_indResult(statistic=-1.8126539343499317, pvalue=0.07641426001850131)\n",
      "Ttest_indResult(statistic=-18.625344245835084, pvalue=4.665556838046147e-23)\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(repel_accuracy_list), np.std(repel_accuracy_list))\n",
    "print(np.mean(none_accuracy_list), np.std(none_accuracy_list))\n",
    "print(np.mean(attract_accuracy_list), np.std(attract_accuracy_list))\n",
    "\n",
    "print()\n",
    "\n",
    "print(ttest_ind(repel_accuracy_list, none_accuracy_list))\n",
    "print(ttest_ind(repel_accuracy_list, attract_accuracy_list))\n",
    "print(ttest_ind(attract_accuracy_list, none_accuracy_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is the model better at predicting any mass class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"model_mass\", \n",
    "                                                                   \"trueMass\", \"'A'\")\n",
    "\n",
    "same_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"model_mass\", \n",
    "                                                                   \"trueMass\", \"'same'\")\n",
    "\n",
    "b_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"model_mass\", \n",
    "                                                                   \"trueMass\", \"'B'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.986111111111111 0.0666087711571211\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "\n",
      "Ttest_indResult(statistic=70.99999999999999, pvalue=1.1611844013922297e-48)\n",
      "Ttest_indResult(statistic=70.99999999999999, pvalue=1.1611844013922297e-48)\n",
      "Ttest_indResult(statistic=nan, pvalue=nan)\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(a_accuracy_list), np.std(a_accuracy_list))\n",
    "print(np.mean(same_accuracy_list), np.std(same_accuracy_list))\n",
    "print(np.mean(b_accuracy_list), np.std(b_accuracy_list))\n",
    "\n",
    "print()\n",
    "\n",
    "print(ttest_ind(a_accuracy_list, same_accuracy_list))\n",
    "print(ttest_ind(a_accuracy_list, b_accuracy_list))\n",
    "print(ttest_ind(b_accuracy_list, same_accuracy_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is the model better at predicting any force class than humans?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5277777777777778 0.3458305443885759\n",
      "0.6041666666666666 0.25937290829143195\n",
      "0.75 0.3227486121839514\n"
     ]
    }
   ],
   "source": [
    "human_repel_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"relationship\", \n",
    "                                                                         \"trueRelationship\", \"'repel'\")\n",
    "\n",
    "human_none_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"relationship\", \n",
    "                                                                        \"trueRelationship\", \"'none'\")\n",
    "\n",
    "human_attract_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"relationship\", \n",
    "                                                                   \"trueRelationship\", \"'attract'\")\n",
    "\n",
    "print(np.mean(human_repel_accuracy_list), np.std(human_repel_accuracy_list))\n",
    "print(np.mean(human_none_accuracy_list), np.std(human_none_accuracy_list))\n",
    "print(np.mean(human_attract_accuracy_list), np.std(human_attract_accuracy_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_relResult(statistic=-7.318998697600914, pvalue=1.9058341561166007e-07)\n",
      "Ttest_relResult(statistic=4.2818917730832595, pvalue=0.00027888703835986467)\n",
      "Ttest_relResult(statistic=-8.75193294508301, pvalue=8.879042557701807e-09)\n"
     ]
    }
   ],
   "source": [
    "print(ttest_rel(repel_accuracy_list, human_repel_accuracy_list))\n",
    "print(ttest_rel(none_accuracy_list, human_none_accuracy_list))\n",
    "print(ttest_rel(attract_accuracy_list, human_attract_accuracy_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is the model better at predicting any mass class than humans?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 0.2545875386086578\n",
      "0.375 0.3236438943814179\n",
      "0.4861111111111111 0.33304385578560547\n",
      "\n"
     ]
    }
   ],
   "source": [
    "human_a_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"mass\", \n",
    "                                                                     \"trueMass\", \"'A'\")\n",
    "\n",
    "human_same_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"mass\", \n",
    "                                                                        \"trueMass\", \"'same'\")\n",
    "\n",
    "human_b_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"mass\", \n",
    "                                                                     \"trueMass\", \"'B'\")\n",
    "\n",
    "print(np.mean(human_a_accuracy_list), np.std(human_a_accuracy_list))\n",
    "print(np.mean(human_same_accuracy_list), np.std(human_same_accuracy_list))\n",
    "print(np.mean(human_b_accuracy_list), np.std(human_b_accuracy_list))\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_relResult(statistic=8.57694401686331, pvalue=1.2724602303790703e-08)\n",
      "Ttest_relResult(statistic=-5.556838403145626, pvalue=1.184889244136472e-05)\n",
      "Ttest_relResult(statistic=-7.000000000000001, pvalue=3.9141861589268866e-07)\n"
     ]
    }
   ],
   "source": [
    "print(ttest_rel(a_accuracy_list, human_a_accuracy_list))\n",
    "print(ttest_rel(same_accuracy_list, human_same_accuracy_list))\n",
    "print(ttest_rel(b_accuracy_list, human_b_accuracy_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
