{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question to be answered:\n",
    "\n",
    "- Is the accuracy of model/human significantly better? In both force and mass questions?\n",
    "- Is the distribution of responses significantly different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import isaac.constants\n",
    "isaac.constants.TQDM_DISABLE = True\n",
    "\n",
    "from torch import nn\n",
    "from isaac.utils import get_cuda_device_if_available\n",
    "import joblib\n",
    "\n",
    "from isaac.dataset import read_dataset, prepare_dataset\n",
    "from isaac.models import MultiBranchModel\n",
    "from isaac.constants import BASIC_TRAINING_COLS, MASS_CLASS_COLS, FORCE_CLASS_COLS\n",
    "from isaac.evaluation import evaluate_saved_model\n",
    "from isaac.statistical_tests import z_test\n",
    "\n",
    "import torch\n",
    "import glob\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = get_cuda_device_if_available()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RTHETA_ATTRS = [obj+\".\"+attr for obj in [\"o1\", \"o2\", \"o3\", \"o4\"] for attr in [\"x\", \"y\", \"r\", \"theta\"]]\n",
    "\n",
    "def add_r_theta_attributes(trials):\n",
    "    for trial in tqdm(trials):\n",
    "        for obj in [\"o1\", \"o2\", \"o3\", \"o4\"]:\n",
    "            trial[obj+\".r\"] = (trial[obj+\".vx\"]**2 + trial[obj+\".vy\"]**2)**0.5\n",
    "            trial[obj+\".theta\"] = (np.arctan2(trial[obj+\".vx\"], trial[obj+\".vy\"]) * 180 / np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_question_accuracy_for_group_of_models(question_type):\n",
    "    normalise_data = True\n",
    "    scaler_path = \"scalers/passive_dual_scaler.sk\"\n",
    "    network_dims = (len(BASIC_TRAINING_COLS), 25, 3, 0.5)\n",
    "    dataset_path = \"../new_exp_data/exp7_passive.h5\"\n",
    "    class_columns = [list(MASS_CLASS_COLS), list(FORCE_CLASS_COLS)]\n",
    "    multiclass = True\n",
    "    seq_end = 2700\n",
    "    step_size = 3\n",
    "    \n",
    "    models = sorted(glob.glob(\"models/train_25_mb/best_\"+question_type+\"_model_seed_*.pt\"))\n",
    "\n",
    "    group_accuracy = []\n",
    "    group_predictions = []\n",
    "    \n",
    "    # trials = read_dataset(dataset_path)\n",
    "    # add_r_theta_attributes(trials)\n",
    "\n",
    "    for model_path in tqdm(models):\n",
    "        accuracies, predicted = evaluate_saved_model(model_path, network_dims, dataset_path, \n",
    "                                                     training_columns=BASIC_TRAINING_COLS, class_columns=class_columns, \n",
    "                                                     step_size=step_size, seq_end=seq_end, scaler_path=scaler_path,\n",
    "                                                     arch=MultiBranchModel, multiclass=multiclass, trials=None)\n",
    "\n",
    "        if question_type == \"mass\":\n",
    "            accuracy = accuracies[0]\n",
    "            predicted = predicted[:, 0]\n",
    "        else:\n",
    "            accuracy = accuracies[1]\n",
    "            predicted = predicted[:, 1]\n",
    "\n",
    "        group_accuracy.append(accuracy)\n",
    "        group_predictions.append(predicted.numpy())\n",
    "\n",
    "    return group_accuracy, group_predictions\n",
    "\n",
    "\n",
    "def get_participant_accuracy_filtering_by_answer(passive_responses, answer_column, question_type_answer, filter_by_class):\n",
    "    \n",
    "    passive_responses = passive_responses.copy().query(question_type_answer+\" == \"+filter_by_class)\n",
    "    return passive_responses[answer_column]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T-test for MASS questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model's predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 1/25 [00:00<00:23,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [69.44444444 63.88888889]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 2/25 [00:01<00:21,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [52.77777778 75.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 3/25 [00:02<00:19,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [50.         72.22222222]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 4/25 [00:03<00:17,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [69.44444444 63.88888889]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 5/25 [00:04<00:16,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [63.88888889 61.11111111]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 6/25 [00:04<00:15,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [52.77777778 72.22222222]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 7/25 [00:05<00:14,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [52.77777778 61.11111111]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 8/25 [00:06<00:13,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [50.         55.55555556]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 9/25 [00:07<00:13,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [47.22222222 52.77777778]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 10/25 [00:08<00:12,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [47.22222222 63.88888889]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 11/25 [00:09<00:11,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [50.         77.77777778]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 12/25 [00:09<00:10,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [55.55555556 77.77777778]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 13/25 [00:10<00:10,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [58.33333333 52.77777778]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 14/25 [00:11<00:09,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [61.11111111 75.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 15/25 [00:12<00:08,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [50.         63.88888889]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 16/25 [00:13<00:07,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [55.55555556 61.11111111]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 17/25 [00:14<00:06,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [41.66666667 66.66666667]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 18/25 [00:14<00:05,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [66.66666667 69.44444444]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 19/25 [00:15<00:04,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [50.         55.55555556]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 20/25 [00:16<00:04,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [52.77777778 66.66666667]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 21/25 [00:17<00:03,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [41.66666667 72.22222222]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 22/25 [00:18<00:02,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [52.77777778 58.33333333]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 23/25 [00:19<00:01,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [50.         61.11111111]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 24/25 [00:19<00:00,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [41.66666667 58.33333333]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:20<00:00,  1.20it/s]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [58.33333333 75.        ]\n",
      "\n",
      "FORCE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 1/25 [00:00<00:20,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [69.44444444 69.44444444]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 2/25 [00:01<00:20,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [66.66666667 69.44444444]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 3/25 [00:02<00:19,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [50.         72.22222222]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 4/25 [00:03<00:17,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [58.33333333 66.66666667]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 5/25 [00:04<00:16,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [61.11111111 66.66666667]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 6/25 [00:05<00:15,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [55.55555556 63.88888889]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 7/25 [00:05<00:14,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [55.55555556 69.44444444]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 8/25 [00:06<00:13,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [55.55555556 50.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 9/25 [00:07<00:12,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [44.44444444 58.33333333]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 10/25 [00:08<00:12,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [44.44444444 58.33333333]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 11/25 [00:09<00:11,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [58.33333333 72.22222222]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 12/25 [00:09<00:10,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [63.88888889 63.88888889]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 13/25 [00:10<00:09,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [55.55555556 61.11111111]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 14/25 [00:11<00:08,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [52.77777778 80.55555556]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 15/25 [00:12<00:08,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [61.11111111 61.11111111]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 16/25 [00:13<00:07,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [55.55555556 63.88888889]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 17/25 [00:14<00:06,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [58.33333333 66.66666667]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 18/25 [00:15<00:06,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [66.66666667 69.44444444]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 19/25 [00:15<00:05,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [52.77777778 61.11111111]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 20/25 [00:16<00:04,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [52.77777778 66.66666667]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 21/25 [00:17<00:03,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [41.66666667 75.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 22/25 [00:18<00:02,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [61.11111111 58.33333333]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 23/25 [00:19<00:01,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [52.77777778 61.11111111]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 24/25 [00:20<00:00,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [44.44444444 61.11111111]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 25/25 [00:20<00:00,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set: [58.33333333 75.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"MASS\")\n",
    "question_type = \"mass\"\n",
    "group_mass_acc, group_mass_prediction = get_question_accuracy_for_group_of_models(question_type)\n",
    "     \n",
    "print(\"\\nFORCE\")\n",
    "question_type = \"force\"\n",
    "group_force_acc, group_force_prediction = get_question_accuracy_for_group_of_models(question_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_mass_prediction = np.array(group_mass_prediction)\n",
    "group_force_prediction = np.array(group_force_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []\n",
    "for question_i in range(group_mass_prediction.shape[1]):\n",
    "    \n",
    "    mass_predictions = list(group_mass_prediction[:, question_i])\n",
    "    question_mass_answers = [(key, mass_predictions.count(key)) for key in range(3)]\n",
    "    question_mass_answers = sorted(question_mass_answers, key=lambda x: x[1], reverse=True)\n",
    "    question_mass_answers = np.hstack(question_mass_answers)\n",
    "    \n",
    "    force_predictions = list(group_force_prediction[:, question_i])\n",
    "    question_force_answers = [(key, force_predictions.count(key)) for key in range(3)]\n",
    "    question_force_answers = sorted(question_force_answers, key=lambda x: x[1], reverse=True)\n",
    "    question_force_answers = np.hstack(question_force_answers)\n",
    "    \n",
    "    answers.append(np.hstack((question_mass_answers, question_force_answers)))\n",
    "    \n",
    "\n",
    "model_answers_df = pd.DataFrame(data=answers, \n",
    "                                columns=[\"model_first_mass_resp\", \"model_first_mass_count\", \n",
    "                                         \"model_second_mass_resp\", \"model_second_mass_count\",\n",
    "                                         \"model_third_mass_resp\", \"model_third_mass_count\",\n",
    "                                         \"model_first_rel_resp\", \"model_first_rel_count\", \n",
    "                                         \"model_second_rel_resp\", \"model_second_rel_count\",\n",
    "                                         \"model_third_rel_resp\", \"model_third_rel_count\"\n",
    "                                         ])\n",
    "\n",
    "model_answers_df = model_answers_df.fillna(0)\n",
    "\n",
    "mass_answer_id_to_str = lambda x: MASS_CLASS_COLS[int(x)]\n",
    "rel_answer_id_to_str = lambda x: FORCE_CLASS_COLS[int(x)]\n",
    "\n",
    "model_answers_df.model_first_mass_resp = model_answers_df.model_first_mass_resp.apply(mass_answer_id_to_str)\n",
    "model_answers_df.model_second_mass_resp = model_answers_df.model_second_mass_resp.apply(mass_answer_id_to_str)\n",
    "model_answers_df.model_third_mass_resp = model_answers_df.model_third_mass_resp.apply(mass_answer_id_to_str)\n",
    "\n",
    "model_answers_df.model_first_rel_resp = model_answers_df.model_first_rel_resp.apply(rel_answer_id_to_str)\n",
    "model_answers_df.model_second_rel_resp = model_answers_df.model_second_rel_resp.apply(rel_answer_id_to_str)\n",
    "model_answers_df.model_third_rel_resp = model_answers_df.model_third_rel_resp.apply(rel_answer_id_to_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_first_mass_resp</th>\n",
       "      <th>model_first_mass_count</th>\n",
       "      <th>model_second_mass_resp</th>\n",
       "      <th>model_second_mass_count</th>\n",
       "      <th>model_third_mass_resp</th>\n",
       "      <th>model_third_mass_count</th>\n",
       "      <th>model_first_rel_resp</th>\n",
       "      <th>model_first_rel_count</th>\n",
       "      <th>model_second_rel_resp</th>\n",
       "      <th>model_second_rel_count</th>\n",
       "      <th>model_third_rel_resp</th>\n",
       "      <th>model_third_rel_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>12</td>\n",
       "      <td>same</td>\n",
       "      <td>11</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "      <td>attract</td>\n",
       "      <td>21</td>\n",
       "      <td>none</td>\n",
       "      <td>4</td>\n",
       "      <td>repel</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>19</td>\n",
       "      <td>same</td>\n",
       "      <td>6</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>attract</td>\n",
       "      <td>25</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>repel</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>24</td>\n",
       "      <td>same</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>attract</td>\n",
       "      <td>25</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>repel</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>same</td>\n",
       "      <td>15</td>\n",
       "      <td>A</td>\n",
       "      <td>9</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>16</td>\n",
       "      <td>repel</td>\n",
       "      <td>6</td>\n",
       "      <td>attract</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>same</td>\n",
       "      <td>18</td>\n",
       "      <td>A</td>\n",
       "      <td>6</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>15</td>\n",
       "      <td>repel</td>\n",
       "      <td>10</td>\n",
       "      <td>attract</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_first_mass_resp  model_first_mass_count model_second_mass_resp  \\\n",
       "0                     A                      12                   same   \n",
       "1                     A                      19                   same   \n",
       "2                     B                      24                   same   \n",
       "3                  same                      15                      A   \n",
       "4                  same                      18                      A   \n",
       "\n",
       "   model_second_mass_count model_third_mass_resp  model_third_mass_count  \\\n",
       "0                       11                     B                       2   \n",
       "1                        6                     B                       0   \n",
       "2                        1                     A                       0   \n",
       "3                        9                     B                       1   \n",
       "4                        6                     B                       1   \n",
       "\n",
       "  model_first_rel_resp  model_first_rel_count model_second_rel_resp  \\\n",
       "0              attract                     21                  none   \n",
       "1              attract                     25                  none   \n",
       "2              attract                     25                  none   \n",
       "3                 none                     16                 repel   \n",
       "4                 none                     15                 repel   \n",
       "\n",
       "   model_second_rel_count model_third_rel_resp  model_third_rel_count  \n",
       "0                       4                repel                      0  \n",
       "1                       0                repel                      0  \n",
       "2                       0                repel                      0  \n",
       "3                       6              attract                      3  \n",
       "4                      10              attract                      0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_answers_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_answers_df.to_hdf(\"../new_exp_data/rnn_answers_with_counts.h5\", key=\"key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_world_variant = []\n",
    "world_id = []\n",
    "\n",
    "for condition_id in range(1, 5):\n",
    "    filename = \"../new_exp_data/physics_data%d.json\" % condition_id\n",
    "    fd = open(filename)\n",
    "    sim_data = json.load(fd)\n",
    "    \n",
    "    for sim in sim_data:\n",
    "        if sim[\"practice\"]:\n",
    "            continue\n",
    "        condition_world_variant.append(sim[\"condition_world_variant\"])\n",
    "        world_id.append(sim[\"world_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_answers_df[\"condition_world_variant\"] = condition_world_variant\n",
    "model_answers_df[\"world_id\"] = world_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_first_mass_resp</th>\n",
       "      <th>model_first_mass_count</th>\n",
       "      <th>model_second_mass_resp</th>\n",
       "      <th>model_second_mass_count</th>\n",
       "      <th>model_third_mass_resp</th>\n",
       "      <th>model_third_mass_count</th>\n",
       "      <th>model_first_rel_resp</th>\n",
       "      <th>model_first_rel_count</th>\n",
       "      <th>model_second_rel_resp</th>\n",
       "      <th>model_second_rel_count</th>\n",
       "      <th>model_third_rel_resp</th>\n",
       "      <th>model_third_rel_count</th>\n",
       "      <th>condition_world_variant</th>\n",
       "      <th>world_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>12</td>\n",
       "      <td>same</td>\n",
       "      <td>11</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "      <td>attract</td>\n",
       "      <td>21</td>\n",
       "      <td>none</td>\n",
       "      <td>4</td>\n",
       "      <td>repel</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>19</td>\n",
       "      <td>same</td>\n",
       "      <td>6</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>attract</td>\n",
       "      <td>25</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>repel</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>24</td>\n",
       "      <td>same</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>attract</td>\n",
       "      <td>25</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>repel</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>same</td>\n",
       "      <td>15</td>\n",
       "      <td>A</td>\n",
       "      <td>9</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>16</td>\n",
       "      <td>repel</td>\n",
       "      <td>6</td>\n",
       "      <td>attract</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>same</td>\n",
       "      <td>18</td>\n",
       "      <td>A</td>\n",
       "      <td>6</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>15</td>\n",
       "      <td>repel</td>\n",
       "      <td>10</td>\n",
       "      <td>attract</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_first_mass_resp  model_first_mass_count model_second_mass_resp  \\\n",
       "0                     A                      12                   same   \n",
       "1                     A                      19                   same   \n",
       "2                     B                      24                   same   \n",
       "3                  same                      15                      A   \n",
       "4                  same                      18                      A   \n",
       "\n",
       "   model_second_mass_count model_third_mass_resp  model_third_mass_count  \\\n",
       "0                       11                     B                       2   \n",
       "1                        6                     B                       0   \n",
       "2                        1                     A                       0   \n",
       "3                        9                     B                       1   \n",
       "4                        6                     B                       1   \n",
       "\n",
       "  model_first_rel_resp  model_first_rel_count model_second_rel_resp  \\\n",
       "0              attract                     21                  none   \n",
       "1              attract                     25                  none   \n",
       "2              attract                     25                  none   \n",
       "3                 none                     16                 repel   \n",
       "4                 none                     15                 repel   \n",
       "\n",
       "   model_second_rel_count model_third_rel_resp  model_third_rel_count  \\\n",
       "0                       4                repel                      0   \n",
       "1                       0                repel                      0   \n",
       "2                       0                repel                      0   \n",
       "3                       6              attract                      3   \n",
       "4                      10              attract                      0   \n",
       "\n",
       "   condition_world_variant  world_id  \n",
       "0                        1       481  \n",
       "1                        1       856  \n",
       "2                        1      1819  \n",
       "3                        1       566  \n",
       "4                        1       821  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_answers_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load human results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning: Warning messages:\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning: 1: \n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning: In value[[3L]](cond) :\n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning: \n",
      " \n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning:  \"getThreads\" not available for .C() for package \"RevoUtilsMath\"\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning: 2: \n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning: 3: \n",
      "  warnings.warn(x, RRuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from rpy2.robjects import r, pandas2ri\n",
    "pandas2ri.activate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/rpy2/robjects/pandas2ri.py:191: FutureWarning: from_items is deprecated. Please use DataFrame.from_dict(dict(items), ...) instead. DataFrame.from_dict(OrderedDict(items)) may be used to preserve the key order.\n",
      "  res = PandasDataFrame.from_items(items)\n"
     ]
    }
   ],
   "source": [
    "rdata_path = \"../new_exp_data/e7_passive.rdata\"\n",
    "r['load'](rdata_path)\n",
    "\n",
    "responses = r[\"tw\"].query(\"practice == 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Percentage of participants that get an answer right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "passive_responses = []\n",
    "\n",
    "for name, df in responses.groupby([\"cond_worldvar\", \"world_id\", \"true_mass\", \"true_rel\"]):\n",
    "    response = [name[0], name[1], name[2], name[3]]\n",
    "\n",
    "    value_counts = df.resp_rel.value_counts().sort_index().sort_values(ascending=False)\n",
    "    for i in range(len(value_counts)):\n",
    "        answer = value_counts.index[i]\n",
    "        response.append(answer)\n",
    "        \n",
    "        if answer == name[3]:\n",
    "            got_it_right = value_counts[i]\n",
    "    response.append(got_it_right / value_counts.sum())\n",
    "            \n",
    "    value_counts = df.resp_mass.value_counts().sort_index().sort_values(ascending=False)\n",
    "    \n",
    "    for i in range(len(value_counts)):\n",
    "        answer = value_counts.index[i]\n",
    "        response.append(answer)\n",
    "        if answer == name[2]:\n",
    "            got_it_right = value_counts[i]\n",
    "            \n",
    "    response.append(got_it_right / value_counts.sum())\n",
    "        \n",
    "    passive_responses.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "passive_responses = pd.DataFrame(data=passive_responses, \n",
    "                                 columns=[\"cond_worldvar\", \"world_id\", \"true_mass\", \"true_rel\",  \n",
    "                                          \"resp_rel\", \"second_resp_rel\", \"third_resp_rel\", \"got_rel_right\",\n",
    "                                          \"resp_mass\", \"second_resp_mass\", \"third_resp_mass\", \"got_mass_right\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cond_worldvar</th>\n",
       "      <th>world_id</th>\n",
       "      <th>true_mass</th>\n",
       "      <th>true_rel</th>\n",
       "      <th>resp_rel</th>\n",
       "      <th>second_resp_rel</th>\n",
       "      <th>third_resp_rel</th>\n",
       "      <th>got_rel_right</th>\n",
       "      <th>resp_mass</th>\n",
       "      <th>second_resp_mass</th>\n",
       "      <th>third_resp_mass</th>\n",
       "      <th>got_mass_right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1218</td>\n",
       "      <td>A</td>\n",
       "      <td>repel</td>\n",
       "      <td>repel</td>\n",
       "      <td>attract</td>\n",
       "      <td>none</td>\n",
       "      <td>0.76</td>\n",
       "      <td>A</td>\n",
       "      <td>same</td>\n",
       "      <td>B</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1736</td>\n",
       "      <td>B</td>\n",
       "      <td>none</td>\n",
       "      <td>repel</td>\n",
       "      <td>none</td>\n",
       "      <td>attract</td>\n",
       "      <td>0.40</td>\n",
       "      <td>B</td>\n",
       "      <td>same</td>\n",
       "      <td>A</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1758</td>\n",
       "      <td>B</td>\n",
       "      <td>repel</td>\n",
       "      <td>repel</td>\n",
       "      <td>attract</td>\n",
       "      <td>none</td>\n",
       "      <td>0.44</td>\n",
       "      <td>B</td>\n",
       "      <td>same</td>\n",
       "      <td>A</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1819</td>\n",
       "      <td>B</td>\n",
       "      <td>attract</td>\n",
       "      <td>attract</td>\n",
       "      <td>repel</td>\n",
       "      <td>none</td>\n",
       "      <td>0.64</td>\n",
       "      <td>B</td>\n",
       "      <td>same</td>\n",
       "      <td>A</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>438</td>\n",
       "      <td>same</td>\n",
       "      <td>repel</td>\n",
       "      <td>repel</td>\n",
       "      <td>none</td>\n",
       "      <td>attract</td>\n",
       "      <td>0.56</td>\n",
       "      <td>same</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cond_worldvar world_id true_mass true_rel resp_rel second_resp_rel  \\\n",
       "0             1     1218         A    repel    repel         attract   \n",
       "1             1     1736         B     none    repel            none   \n",
       "2             1     1758         B    repel    repel         attract   \n",
       "3             1     1819         B  attract  attract           repel   \n",
       "4             1      438      same    repel    repel            none   \n",
       "\n",
       "  third_resp_rel  got_rel_right resp_mass second_resp_mass third_resp_mass  \\\n",
       "0           none           0.76         A             same               B   \n",
       "1        attract           0.40         B             same               A   \n",
       "2           none           0.44         B             same               A   \n",
       "3           none           0.64         B             same               A   \n",
       "4        attract           0.56      same                B               A   \n",
       "\n",
       "   got_mass_right  \n",
       "0            0.52  \n",
       "1            0.52  \n",
       "2            0.72  \n",
       "3            0.60  \n",
       "4            0.36  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passive_responses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "passive_responses[\"cond_worldvar\"] = passive_responses[\"cond_worldvar\"].astype(\"int64\")\n",
    "passive_responses[\"world_id\"] = passive_responses[\"world_id\"].astype(\"int64\")\n",
    "\n",
    "passive_responses = passive_responses.merge(model_answers_df, left_on=[\"cond_worldvar\", \"world_id\"], right_on=[\"condition_world_variant\", \"world_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Percentage of models that get an answer right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_that_got_mass_question_right = []\n",
    "\n",
    "for i, answer in enumerate(passive_responses.true_mass):\n",
    "    if passive_responses.model_first_mass_resp.iloc[i] == answer:\n",
    "        models_that_got_mass_question_right.append(passive_responses.model_first_mass_count.iloc[i])\n",
    "    elif passive_responses.model_second_mass_resp.iloc[i] == answer:\n",
    "        models_that_got_mass_question_right.append(passive_responses.model_second_mass_count.iloc[i])\n",
    "    elif passive_responses.model_third_mass_resp.iloc[i] == answer:\n",
    "        models_that_got_mass_question_right.append(passive_responses.model_third_mass_count.iloc[i])\n",
    "\n",
    "        \n",
    "models_that_got_rel_question_right = []\n",
    "        \n",
    "for i, answer in enumerate(passive_responses.true_rel):\n",
    "    if passive_responses.model_first_rel_resp.iloc[i] == answer:\n",
    "        models_that_got_rel_question_right.append(passive_responses.model_first_rel_count.iloc[i])\n",
    "        \n",
    "    elif passive_responses.model_second_rel_resp.iloc[i] == answer:\n",
    "        models_that_got_rel_question_right.append(passive_responses.model_second_rel_count.iloc[i])\n",
    "        \n",
    "    elif passive_responses.model_third_rel_resp.iloc[i] == answer:\n",
    "        models_that_got_rel_question_right.append(passive_responses.model_third_rel_count.iloc[i])\n",
    "        \n",
    "\n",
    "passive_responses[\"models_got_mass_right\"] = np.array(models_that_got_mass_question_right) / 25\n",
    "passive_responses[\"models_got_rel_right\"] = np.array(models_that_got_rel_question_right) / 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cond_worldvar', 'world_id', 'true_mass', 'true_rel', 'resp_rel',\n",
       "       'second_resp_rel', 'third_resp_rel', 'got_rel_right', 'resp_mass',\n",
       "       'second_resp_mass', 'third_resp_mass', 'got_mass_right',\n",
       "       'model_first_mass_resp', 'model_first_mass_count',\n",
       "       'model_second_mass_resp', 'model_second_mass_count',\n",
       "       'model_third_mass_resp', 'model_third_mass_count',\n",
       "       'model_first_rel_resp', 'model_first_rel_count',\n",
       "       'model_second_rel_resp', 'model_second_rel_count',\n",
       "       'model_third_rel_resp', 'model_third_rel_count',\n",
       "       'condition_world_variant', 'models_got_mass_right',\n",
       "       'models_got_rel_right'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passive_responses.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "passive_responses[\"model_mass\"] = passive_responses[\"model_first_mass_resp\"]\n",
    "passive_responses[\"model_relationship\"] = passive_responses[\"model_first_rel_resp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_mass_accuracy_list = passive_responses.got_mass_right\n",
    "human_force_accuracy_list = passive_responses.got_rel_right\n",
    "\n",
    "model_mass_accuracy_list = passive_responses.models_got_mass_right\n",
    "model_force_accuracy_list = passive_responses.models_got_rel_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37839031339031337 ± 0.145973580677441\n",
      "0.5366666666666666 ± 0.2839992175263086\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(human_mass_accuracy_list), \"±\", np.std(human_mass_accuracy_list))\n",
    "print(np.mean(model_mass_accuracy_list), \"±\", np.std(model_mass_accuracy_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5462250712250714 ± 0.176816239172785\n",
      "0.6566666666666667 ± 0.21320308523929843\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(human_force_accuracy_list), \"±\", np.std(human_force_accuracy_list))\n",
    "print(np.mean(model_force_accuracy_list), \"±\", np.std(model_force_accuracy_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform t-test on overall accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null hypothesis (opposite of what we want to prove): accuracies are not significantly different\n",
    "# Alternative hypothesis: accuracies are significantly different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind, ttest_rel, f_oneway"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is the model significantly better answering mass questions than humans?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=-3.6873191331691264, pvalue=0.000763240022957818)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_rel(human_mass_accuracy_list, model_mass_accuracy_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is the model significantly better answering force questions than humans?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=-2.364560857365549, pvalue=0.023727816753575937)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_rel(human_force_accuracy_list, model_force_accuracy_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is the model significantly better answering force questions than mass questions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-1.9991187485802633, pvalue=0.049479134569990736)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_ind(model_mass_accuracy_list, model_force_accuracy_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Are correct guesses / errors correlated between humans and model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chisquare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "passive_responses[\"model_mass_correct_guesses\"] = (passive_responses[\"model_mass\"] == passive_responses[\"true_mass\"])\n",
    "passive_responses[\"model_force_correct_guesses\"] = (passive_responses[\"model_relationship\"] == passive_responses[\"true_rel\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "passive_responses[\"corRel\"] = (passive_responses[\"resp_rel\"] == passive_responses[\"true_rel\"])\n",
    "passive_responses[\"corMass\"] = (passive_responses[\"resp_mass\"] == passive_responses[\"true_mass\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5277777777777778\n",
      "0.6111111111111112\n"
     ]
    }
   ],
   "source": [
    "mass_coincidence = (passive_responses[\"resp_mass\"] == passive_responses[\"model_mass\"]).mean()\n",
    "force_coincidence = (passive_responses[\"resp_rel\"] == passive_responses[\"model_relationship\"]).mean()\n",
    "\n",
    "print(mass_coincidence)\n",
    "print(force_coincidence)\n",
    "\n",
    "# FLAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_for_independence(first_answers, second_answers):\n",
    "    both_correct = (first_answers & second_answers).sum()\n",
    "    both_wrong = (~first_answers & ~second_answers).sum()\n",
    "    first_correct_second_wrong = (first_answers & ~second_answers).sum()\n",
    "    first_wrong_second_correct = (~first_answers & second_answers).sum()\n",
    "    matrix = np.array([[both_correct, first_correct_second_wrong], [first_wrong_second_correct, both_wrong]])\n",
    "    \n",
    "    accuracy_first = first_answers.sum() / len(first_answers)\n",
    "    accuracy_sec = second_answers.sum() / len(second_answers)\n",
    "    total_answers = len(first_answers)\n",
    "    \n",
    "    \n",
    "    expected_first = np.array([[accuracy_first/2, accuracy_first/2], [(1 - accuracy_first)/2, (1 - accuracy_first)/2]])\n",
    "    expected_sec = np.array([[accuracy_sec/2, (1 - accuracy_sec)/2], [accuracy_sec/2, (1 - accuracy_sec)/2]])\n",
    "    expected = expected_first * expected_sec\n",
    "    expected /= np.sum(expected)\n",
    "    expected *= total_answers\n",
    "    \n",
    "    chisquare_results = chisquare(matrix, expected, axis=None)\n",
    "    print(\"Expected\")\n",
    "    print(expected)\n",
    "    print(\"Reality\")\n",
    "    print(matrix)\n",
    "    return chisquare_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected\n",
      "[[23.36111111  5.63888889]\n",
      " [ 5.63888889  1.36111111]]\n",
      "Reality\n",
      "[[22  7]\n",
      " [ 7  0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=2.097502972651607, pvalue=0.5524180941443271)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_for_independence(passive_responses[\"corRel\"], passive_responses[\"model_force_correct_guesses\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected\n",
      "[[ 7.22222222  5.77777778]\n",
      " [12.77777778 10.22222222]]\n",
      "Reality\n",
      "[[11  2]\n",
      " [ 9 14]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=6.959197324414716, pvalue=0.07320972635128)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_for_independence(passive_responses[\"corMass\"], passive_responses[\"model_mass_correct_guesses\"])\n",
    "#FLAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_for_coincidence(first_answers, second_answers, true_answers):\n",
    "    \n",
    "    matrix = []\n",
    "    all_classes = sorted(first_answers.unique())\n",
    "    \n",
    "    for class_name in all_classes:\n",
    "        this_class_coincidences = []\n",
    "        for second_class_name in all_classes:\n",
    "            n_coincidences = ((first_answers == class_name) & (second_answers == second_class_name)).sum()\n",
    "            this_class_coincidences.append(n_coincidences)\n",
    "            \n",
    "        matrix.append(this_class_coincidences)\n",
    "    \n",
    "    matrix = np.array(matrix)\n",
    "    \n",
    "    expected = []    \n",
    "    for class_name in all_classes:\n",
    "        this_class_prob = []\n",
    "        for second_class_name in all_classes:\n",
    "            prob = 0\n",
    "            for true_class in all_classes:\n",
    "                # p_humans(first_class\\true_class) * p_rnn(first_class\\true_class)\n",
    "                class_examples = (true_answers == true_class).sum()\n",
    "                \n",
    "                p_class = class_examples / len(first_answers)\n",
    "                p_first_given_class = ((first_answers == class_name) & (true_answers == true_class)).sum() / class_examples\n",
    "                p_second_given_class = ((second_answers == second_class_name) & (true_answers == true_class)).sum() / class_examples\n",
    "                val = p_class * p_first_given_class * p_second_given_class\n",
    "                \n",
    "                prob += val\n",
    "\n",
    "            this_class_prob.append(prob)\n",
    "        expected.append(this_class_prob)\n",
    "    expected = np.array(expected) \n",
    "    expected /= np.sum(expected)\n",
    "    expected *= len(first_answers)\n",
    "    print(\"Expected:\")\n",
    "    print(all_classes)\n",
    "    print(expected)\n",
    "    print()\n",
    "    print(\"Reality:\")\n",
    "    print(all_classes)\n",
    "    print(matrix)\n",
    "    chisquare_results = chisquare(matrix, expected, axis=None)\n",
    "    \n",
    "    return chisquare_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected:\n",
      "['attract', 'none', 'repel']\n",
      "[[11.          3.75        0.25      ]\n",
      " [ 0.          5.91666667  1.08333333]\n",
      " [ 0.          7.33333333  6.66666667]]\n",
      "\n",
      "Reality:\n",
      "['attract', 'none', 'repel']\n",
      "[[11  4  0]\n",
      " [ 0  5  2]\n",
      " [ 0  8  6]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hector/miniconda3/envs/diss/lib/python3.5/site-packages/scipy/stats/stats.py:4567: RuntimeWarning: invalid value encountered in true_divide\n",
      "  terms = (f_obs - f_exp)**2 / f_exp\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=nan, pvalue=nan)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_for_coincidence(passive_responses[\"resp_rel\"], passive_responses[\"model_relationship\"], passive_responses[\"true_rel\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected:\n",
      "['A', 'B', 'same']\n",
      "[[4.16666667 3.33333333 5.5       ]\n",
      " [3.75       4.83333333 5.41666667]\n",
      " [2.08333333 3.83333333 3.08333333]]\n",
      "\n",
      "Reality:\n",
      "['A', 'B', 'same']\n",
      "[[7 2 4]\n",
      " [2 7 5]\n",
      " [1 3 5]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=6.625007420689579, pvalue=0.5775775702624837)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_for_coincidence(passive_responses[\"resp_mass\"], passive_responses[\"model_mass\"], passive_responses[\"true_mass\"])\n",
    "# FLAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is the model better at predicting any force class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "repel_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"models_got_rel_right\", \n",
    "                                                                   \"true_rel\", \"'repel'\")\n",
    "\n",
    "none_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"models_got_rel_right\", \n",
    "                                                                   \"true_rel\", \"'none'\")\n",
    "\n",
    "attract_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"models_got_rel_right\", \n",
    "                                                                   \"true_rel\", \"'attract'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5233333333333333 0.21507104769251384\n",
      "0.6566666666666666 0.13211947455070944\n",
      "0.79 0.19261360284258222\n",
      "\n",
      "Ttest_indResult(statistic=-1.7519733256128291, pvalue=0.09370781302830289)\n",
      "Ttest_indResult(statistic=-3.0633583242699354, pvalue=0.005691672124483616)\n",
      "Ttest_indResult(statistic=1.8932832289250123, pvalue=0.0715480390565109)\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(repel_accuracy_list), np.std(repel_accuracy_list))\n",
    "print(np.mean(none_accuracy_list), np.std(none_accuracy_list))\n",
    "print(np.mean(attract_accuracy_list), np.std(attract_accuracy_list))\n",
    "\n",
    "print()\n",
    "\n",
    "print(ttest_ind(repel_accuracy_list, none_accuracy_list))\n",
    "print(ttest_ind(repel_accuracy_list, attract_accuracy_list))\n",
    "print(ttest_ind(attract_accuracy_list, none_accuracy_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Are humans better at predicting any force class? And compared to RNNs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5727350427350427 0.13531888148325485\n",
      "0.38777777777777783 0.10039803172690473\n",
      "0.6781623931623932 0.14894697893841963\n",
      "\n",
      "Ttest_indResult(statistic=3.640639395027706, pvalue=0.0014428896714880582)\n",
      "Ttest_indResult(statistic=-1.7375664164447775, pvalue=0.09626821719795242)\n",
      "Ttest_indResult(statistic=5.361722481943239, pvalue=2.204329106568638e-05)\n"
     ]
    }
   ],
   "source": [
    "human_repel_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"got_rel_right\", \n",
    "                                                                         \"true_rel\", \"'repel'\")\n",
    "\n",
    "human_none_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"got_rel_right\", \n",
    "                                                                        \"true_rel\", \"'none'\")\n",
    "\n",
    "human_attract_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"got_rel_right\", \n",
    "                                                                   \"true_rel\", \"'attract'\")\n",
    "\n",
    "print(np.mean(human_repel_accuracy_list), np.std(human_repel_accuracy_list))\n",
    "print(np.mean(human_none_accuracy_list), np.std(human_none_accuracy_list))\n",
    "print(np.mean(human_attract_accuracy_list), np.std(human_attract_accuracy_list))\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "print(ttest_ind(human_repel_accuracy_list, human_none_accuracy_list))\n",
    "print(ttest_ind(human_repel_accuracy_list, human_attract_accuracy_list))\n",
    "print(ttest_ind(human_attract_accuracy_list, human_none_accuracy_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_relResult(statistic=-0.5291850077677979, pvalue=0.607190819213975)\n",
      "Ttest_relResult(statistic=4.788593129525713, pvalue=0.0005635761649337808)\n",
      "Ttest_relResult(statistic=1.695568588698561, pvalue=0.11805184220926189)\n"
     ]
    }
   ],
   "source": [
    "print(ttest_rel(repel_accuracy_list, human_repel_accuracy_list))\n",
    "print(ttest_rel(none_accuracy_list, human_none_accuracy_list))\n",
    "print(ttest_rel(attract_accuracy_list, human_attract_accuracy_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is the model better at predicting any mass class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"models_got_mass_right\", \n",
    "                                                                   \"true_mass\", \"'A'\")\n",
    "\n",
    "same_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"models_got_mass_right\", \n",
    "                                                                   \"true_mass\", \"'same'\")\n",
    "\n",
    "b_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"models_got_mass_right\", \n",
    "                                                                   \"true_mass\", \"'B'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5166666666666667 0.29141417642630607\n",
      "0.39333333333333337 0.2208066021557226\n",
      "0.7000000000000001 0.24630604269214884\n",
      "\n",
      "Ttest_indResult(statistic=1.118786463923166, pvalue=0.27529874421091305)\n",
      "Ttest_indResult(statistic=-1.5935792331068999, pvalue=0.12529739565212536)\n",
      "Ttest_indResult(statistic=3.074752405610619, pvalue=0.005542451189118525)\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(a_accuracy_list), np.std(a_accuracy_list))\n",
    "print(np.mean(same_accuracy_list), np.std(same_accuracy_list))\n",
    "print(np.mean(b_accuracy_list), np.std(b_accuracy_list))\n",
    "\n",
    "print()\n",
    "\n",
    "print(ttest_ind(a_accuracy_list, same_accuracy_list))\n",
    "print(ttest_ind(a_accuracy_list, b_accuracy_list))\n",
    "print(ttest_ind(b_accuracy_list, same_accuracy_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Are humans better at predicting any mass class? And compared to RNNs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4100427350427351 0.14185875067409623\n",
      "0.30391025641025643 0.11751739115262044\n",
      "0.42121794871794865 0.14699406576210686\n",
      "\n",
      "\n",
      "Ttest_indResult(statistic=1.9108454864102784, pvalue=0.0691424586904233)\n",
      "Ttest_indResult(statistic=-0.1814353668752333, pvalue=0.8576870862868097)\n",
      "Ttest_indResult(statistic=2.0673466990693723, pvalue=0.050664413609717754)\n"
     ]
    }
   ],
   "source": [
    "human_a_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"got_mass_right\", \n",
    "                                                                     \"true_mass\", \"'A'\")\n",
    "\n",
    "human_same_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"got_mass_right\", \n",
    "                                                                        \"true_mass\", \"'same'\")\n",
    "\n",
    "human_b_accuracy_list = get_participant_accuracy_filtering_by_answer(passive_responses, \"got_mass_right\", \n",
    "                                                                     \"true_mass\", \"'B'\")\n",
    "\n",
    "print(np.mean(human_a_accuracy_list), np.std(human_a_accuracy_list))\n",
    "print(np.mean(human_same_accuracy_list), np.std(human_same_accuracy_list))\n",
    "print(np.mean(human_b_accuracy_list), np.std(human_b_accuracy_list))\n",
    "\n",
    "print()\n",
    "\n",
    "print()\n",
    "\n",
    "print(ttest_ind(human_a_accuracy_list, human_same_accuracy_list))\n",
    "print(ttest_ind(human_a_accuracy_list, human_b_accuracy_list))\n",
    "print(ttest_ind(human_b_accuracy_list, human_same_accuracy_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_relResult(statistic=1.1748586914436814, pvalue=0.2648568286198724)\n",
      "Ttest_relResult(statistic=1.4025056601341677, pvalue=0.18835103389704)\n",
      "Ttest_relResult(statistic=4.85866796379548, pvalue=0.0005037380051173388)\n"
     ]
    }
   ],
   "source": [
    "print(ttest_rel(a_accuracy_list, human_a_accuracy_list))\n",
    "print(ttest_rel(same_accuracy_list, human_same_accuracy_list))\n",
    "print(ttest_rel(b_accuracy_list, human_b_accuracy_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do model's correct answers correspond to examples that a higher percentage of humans guess?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mass responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=4.659555307287202, pvalue=0.03802985826378633)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_mass_correct_guesses = passive_responses.query(\"model_mass_correct_guesses\")[\"got_mass_right\"]\n",
    "post_mass_wrong_guesses = passive_responses.query(\"not model_mass_correct_guesses\")[\"got_mass_right\"]\n",
    "\n",
    "f_oneway(post_mass_correct_guesses, post_mass_wrong_guesses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 16)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(post_mass_correct_guesses), len(post_mass_wrong_guesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Force responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=1.1022776604149753, pvalue=0.3011724606372818)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_force_correct_guesses = passive_responses.query(\"model_force_correct_guesses\")['got_rel_right']\n",
    "post_force_wrong_guesses = passive_responses.query(\"not model_force_correct_guesses\")['got_rel_right']\n",
    "\n",
    "f_oneway(post_force_correct_guesses, post_force_wrong_guesses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 7)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(post_force_correct_guesses), len(post_force_wrong_guesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Are %RNNs and %participants getting a question correct correlated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.45199166],\n",
       "       [0.45199166, 1.        ]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(passive_responses.models_got_mass_right, passive_responses.got_mass_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f857d464e10>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "passive_responses.plot(kind=\"scatter\", x=\"models_got_mass_right\", y=\"got_mass_right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.00484687],\n",
       "       [0.00484687, 1.        ]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(passive_responses.models_got_rel_right, passive_responses.got_rel_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f857ca8fcc0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAELCAYAAADdriHjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAHeRJREFUeJzt3X+UXHWZ5/H3p0NIMiRATFrWTSckShwngzFoT5QJq4yCE5izyWpcB5RVZtUcHaNzVOTH6FGMelT8wczsyY7GORxEZ4xIzkiraHQRj8oRTUdCI9Fob0TSxNWYSZBI0nboZ/+o21C3UlVd1V23bv34vM5pqHvr1q2nb93U0/f7/d7nq4jAzMxsQk/eAZiZWWtxYjAzsxQnBjMzS3FiMDOzFCcGMzNLcWIwM7MUJwYzM0txYjAzsxQnBjMzSzkl7wCmYuHChbF06dK8wzAzayu7du36bUT0TrZdWyaGpUuXMjg4mHcYZmZtRdIva9nOTUlmZpbixGBmZilODGZmluLEYGZmKU4MZmaW4sRgZmYpTgxmZpbixGBmZilODGbWdQ4dHeW+/Uc4dHQ071BaUlve+WxmNlW3736Ya7YPMbOnh7HxcW7YsJJ1qxblHVZL8RWDmXWNQ0dHuWb7EMfHxnl09ATHx8a5evuQrxxKODGYWdcYOXyMmT3pr72ZPT2MHD6WU0StKfPEIGmtpL2ShiVdW+b5syXdKWlI0rcl9WUdk5l1p775cxgbH0+tGxsfp2/+nJwiak2ZJgZJM4AtwCXACuBySStKNvsYcEtErAQ2Ax/KMiYz614L5s7ihg0rmT2zh3mzTmH2zB5u2LCSBXNn5R1aS8m683k1MBwR+wAkbQPWA3uKtlkBvC15fBfwpYxjMrMutm7VItacs5CRw8fomz/HSaGMrJuSFgH7i5ZHknXF7gM2JI9fBsyTtKB0R5I2ShqUNHjw4MFMgjWz7rBg7iyes/hMJ4UKsk4MKrMuSpavAl4k6V7gRcDDwImTXhSxNSL6I6K/t3fSCYjMzGyKsm5KGgEWFy33AQeKN4iIA8DLASTNBTZExCMZx2VmZhVkfcWwE1guaZmkU4HLgIHiDSQtlDQRx3XATRnHZGZmVWSaGCLiBLAJ2AH8BLg1Ih6QtFnSumSzC4G9kn4GnAV8MMuYzMysOkWUNvm3vv7+/hgcHMw7DDOztiJpV0T0T7ad73w2M7MUJwYzM0txYjAzsxQnBjMzS3FiMDOzFCcGMzNLcWIwM6tDN0wL6qk9zcxq1C3TgvqKwcysBt00LagTg5lZDbppWlAnBjOzGnTTtKBODGZmNeimaUHd+WxmVqNumRbUicHMrA4L5s7q2IQwwU1JZmaW4sRgZmYpTgxmZpaSeWKQtFbSXknDkq4t8/wSSXdJulfSkKRLs47JzMwqyzQxSJoBbAEuAVYAl0taUbLZuynMBX0ecBnwv7OMycwsD+1UYynrUUmrgeGI2AcgaRuwHthTtE0ApyePzwAOZByTmVlTtVuNpaybkhYB+4uWR5J1xa4HrpA0AtwBvCXjmMy6Qjv9hdrJ2rHGUtZXDCqzLkqWLwdujoiPSzof+KykcyMide+5pI3ARoAlS5ZkEqxZp2i3v1A72USNpeM8+ZU2UWOpVe+HyPqKYQRYXLTcx8lNRa8DbgWIiO8Ds4GFpTuKiK0R0R8R/b29vRmFa9b+2vEv1E7WjjWWsk4MO4HlkpZJOpVC5/JAyTYPAS8BkPQnFBLDwYzjMutY3VQFtB20Y42lTJuSIuKEpE3ADmAGcFNEPCBpMzAYEQPAO4BPS3obhWamKyOitLnJzGrUjn+hdrp2q7GkdvwO7u/vj8HBwbzDMGtZA7sf5mr3MVgJSbsion+y7VxEz6wDrVu1iBVPO53d+4+wavGZnHPWvLxDsjbixGDWgTwqyabDtZLMOoxHJdl0dW1i8M0/rSOPz6KTP3+PSuoseZyrXdmU5Mvs1pHHZ9Hpn79HJXWOvM7Vrrti8GV268jjs+iGz78dx83byfI8V7vuiqEdb0/vVHl8Ft3y+bfbuHk7WZ7natclBl9mt448Potu+vy7YW7iTpbnudp1TUm+zG4deXwW/vytXeR5rnbtnc+Hjo76MrtF5PFZ+PO3dtHIc9V3Pk/Cl9mtI4/Pwp+/tYs8ztWua0oyM7PqnBjMzCzFicHMzFKcGMzMLMWJwczMUpwYzMwsxYnBzMxSMk8MktZK2itpWNK1ZZ6/UdLu5Odnko5kHZOZmVWW6Q1ukmYAW4CLgRFgp6SBiNgzsU1EvK1o+7cA52UZk5mZVZf1FcNqYDgi9kXEH4BtwPoq218OfD7jmMzMrIqsE8MiYH/R8kiy7iSSzgaWAd/KOCYzM6si68SgMusqVe27DLgtIh4vuyNpo6RBSYMHDx5sWIBmZpaWdWIYARYXLfcBBypsexlVmpEiYmtE9EdEf29vbwNDNDOzYlknhp3AcknLJJ1K4ct/oHQjSX8MzAe+n3E8ZmY2iUwTQ0ScADYBO4CfALdGxAOSNktaV7Tp5cC2aMfJIczMOkzm8zFExB3AHSXr3lOyfH3WcZiZWW1857OZmaU4MZiZWYoTg5mZpTgxmJlZSs2JQdJna1lnZmbtrZ4rhj8tXkgK5D2vseGYmVneJk0Mkq6T9CiwUtLvkp9Hgd8At2ceoZmZNdWkiSEiPhQR84CPRsTpyc+8iFgQEdc1IUYzs6516Ogo9+0/wqGjo017z5pvcIuI6yQtAs4ufl1EfCeLwMzMut3tux/mmu1DzOzpYWx8nBs2rGTdqrIFqhuq5sQg6cMUah3tASYqoAbgxGBm1mCHjo5yzfYhjo+Nc5xxAK7ePsSacxayYO6sTN+7npIYLwP+OCKadz1jZtalRg4fY2ZPzxNJAWBmTw8jh49lnhjqGZW0D5iZVSBmU5FH+6tZM/TNn8PY+Hhq3dj4OH3z52T+3pNeMUj6XxSajB4Ddku6E3jiX2FEvDW78Mwqy6v91awZFsydxQ0bVnJ1yTme9dUC1NaUNJj8fxdl5lIwy0Oe7a9mzbJu1SLWnLOQkcPH6Js/p2nn9qSJISI+04xAzOqRZ/urWTMtmDur6ed0PaOS7ufk+ZofoXBF8YGIONTIwMyqybP91azT1dP5/DXgq8Crk58vA98F/h9wc8MjM6tiov119swe5s06hdkze5rW/mrW6eoZrromItYULd8v6e6IWCPpikovkrQW+EdgBvAvEfHhMtu8EriewhXJfRHxqjrisi6VV/urWaerJzHMlfT8iPgBgKTVwNzkuRPlXpAU2tsCXAyMADslDUTEnqJtlgPXUUg8hyU9dQq/h3WpPNpfzTpdPYnh9cBNkuYCAn4HvF7SacCHKrxmNTAcEfsAJG0D1lO4e3rCG4AtEXEYICJ+U9+vYGZmjVRPraSdwLMlnQEoIo4UPX1rhZctAvYXLY8Azy/Z5pkAku6m0Nx0fUR8vda4zMyssWq5we2KiPicpLeXrAcgIj5R7eVl1pWObDoFWA5cCPQB35V0bkniQdJGYCPAkiVLJgvbzMymqJZRSacl/59X4aeaEWBx0XIfcKDMNrdHxFhE/ALYSyFRpETE1ojoj4j+3t7eGsI2M7OpqOUGt08lnci/i4gb69z/TmC5pGXAwxSqs5aOOPoScDlws6SFFJqW9tX5PtbGDh0d9cgisxZSUx9DRDwuaR1QV2KIiBOSNgE7KPQf3BQRD0jaDAxGxEDy3EslTZTzfmczbpbzl1FrcL2jyflctWZTRGmTf4UNpQ8CZwBfAH4/sT4ifpRNaJX19/fH4ODg5BtW4C+j1nDo6ChrPvItjo89eQfz7Jk93H3Ni/0FmPC5ao0kaVdE9E+2XT3DVf88+f/monUBvLiewPLm4mutw/WOqvO5anmpZ7jqX1R7XtJr26Hgnr+MWofrHVXnc9XyUk+tpMn8XQP3lRl/GbUO1zuqzueq5aWepqTJlLtnoeXkOfmFnazd6h01syN44lx9521DzOgRj49HXeeqO61tqhqZGGrrxW4B7fZl1Onapd5RHh3BMfHfEPX8E3OntU1HI5uS2uKKYcKCubN4zuIz2+ILyfJX3BH86OgJjo+Nc/X2oUznmp54z9ETwWNjjzN6Imp6zzxitc7SyMRwdwP3ZdZSJjqCi010BLfae+YRq3WWWmolvb3a8xO1kiJiU6OCMms1eXQET/U93Wlt01XLFUOlGkm11EqyHB06Osp9+4+4CaEB8hhBNdX3nG6sPm+s5jufW8l073zuBu58zEYeI32m+p5TeZ3Pm85W653P9ZTEeCbwz8BZEXGupJXAuoj4wPRCrZ8TQ3UuNWFT4fOm89WaGOrpfP40hSk4xwAiYohCtVRrMe58tKnweWMT6kkMfxQRPyxZV3auZ8uXOx9tKnze2IR6EsNvJT2D5C4bSa8AfpVJVDYtLjVhU+HzxibU08fwdGArhSqrh4FfAK+OiF9mF1557mOojUsi2FT4vOlcDS27LakH6I+IiySdBvRExKPTDdKy1S6lJqy1+LyxmpqSImIc2JQ8/r2TgplZ56qnj+Gbkq6StFjSUyZ+MovMzMxyUU9i+J/Am4HvALuSn0kb+iWtlbRX0rCka8s8f6Wkg5J2Jz+vryMmMzNrsHpmcFtW7XlJF0fEN0vWzQC2ABcDI8BOSQMRsafk5V9wrSXrdM3u1B3+9aPs3n+EVYvP5JyzXL3GatfI+Rg+AnyzZN1qYDgi9gFI2gasB0oTg1lHa3apifd86X5uueehJ5Zfc/4SNq9/dmbvZ50l6/kYFgH7i5ZHknWlNkgaknSbpMUNjMksd82eH2H414+mkgLALd9/iOFfe8yI1aaRiaHcDRHlkkXpdl8GlkbESuD/AJ8pt3NJGyUNSho8ePDg9CI1a6Jml5rYvf9IXevNSjUyMZQzAhRfAfQBB4o3iIhDETHxp9OngeeV21FEbI2I/ojo7+3tzSRYsyw0u9TEqsVn1rXerFTNiUHSSb1lJeseLPOyncByScsknUqh6N5AyT6eVrS4DvhJrTGZtYNml5o456x5vOb8Jal1rzl/SUd2QHfD3BF5/I71lMT4UUQ8d7J1ZV53KfAPwAzgpoj4oKTNwGBEDEj6EIWEcAL4D+BNEfHTavt0SQxrRx6V1FjdMHdEo3/Hhs3HIOk/Uegw/hzwKp7sNzgd+GREPGvKUU6RE4NZd+uGuSOy+B0bWSvpL4ErKfQPfKJo/aPA308pOjOzaZjo0D/Ok1+aEx36nZIY8vwdJ00MEfEZ4DOSNkTE9kyjMTOrQTfMHZHn71jPqKQ7JX1iYsiopI9LOiOzyMxaUDd0draDbpg7Is/fsZ7O5+3Aj3nyPoP/ATwnIl6eUWwVuY/B8tANnZ3tphvmjmjk79jQ+RgSz4iIDUXL75O0u/7QzNpP8d3LE22+V28fYs05Czv2C6kddMPcEXn8jvU0JR2TdMHEgqQ1gGcJt67Q7LuXzfJUzxXDG4FbivoVDgOvbXxIZq2nGzo7zSbUkxheQqF/YW6yfBT4M0k9EeEmJetoEx2BV5f0MXR6M4Z1p3oSQ3/yM0DhJrdXUSh58UZJX4yIGzKIz6xlrFu1iDXnLGx6Z+dUOx+7oWPWslFPYlgAPDcijgJIei9wG/BCCrO5OTFYx2t2R+BUR0J5BJVNRz2dz0uAPxQtjwFnR8QxwIO6zRpsqvM4NHv+B+s89Vwx/Btwj6Tbk+X/Cnxe0ml4RjazhptqSYRuKBdh2apnzuf3S7oDuIBCH8MbI2LiLrNXZxGcTY/bmNvbVEdCeQSVTVddcz5HxC4K/QnW4tzG3P6mOhLKI6hsumouidFKXBKjum4oSdxNPCrJGiWLkhjWJtzG3FmmOhKqG8pFWDaynvPZcuA2ZjObjswTg6S1kvZKGpZ0bZXtXiEpJE16mWPVdUNJYjPLTqZNSZJmAFuAi4ERYKekgYjYU7LdPOCtwA+yjKeb5HWXrtlUuD+ktWTdx7AaGI6IfQCStgHrOfm+h/dTuHP6qozj6SpuY7Z24BF0rSfrpqRFwP6i5ZFk3RMknQcsjoivZByLmbUY36XdmrJODCqz7onxsZJ6gBuBd0y6I2njxLSiBw8ebGCIZpYXz3PRmrJODCPA4qLlPuBA0fI84Fzg25IeBF4ADJTrgI6IrRHRHxH9vb29GYZsVpnnfG4sj6BrTVn3MewElktaBjwMXEahXDcAEfEIsHBiWdK3gauKSm2YtQy3hTee79JuTZkmhog4IWkTsAOYAdwUEQ9I2gwMRsRAlu9v1iie8zk7HkHXejK/8zki7gDuKFn3ngrbXph1PGZT4bvJs+URdK3Fdz6b1cBt4dZNnBjMauC7ya2buIieWY3cFm7dwonBrA5uC7du4KYkMzNLcWIwM7MUJwYzM0txYjAzsxQnBjMzS3FiMDOzFCcGM0txBVnzfQxm9gRXkDXwFYOZJTybmk1wYjBrklZvovFsajbBTUlmTdAOTTR98+dwbOxEat2xsROuINuFfMVglrF2aqKRVHXZuoMTg1nG2qWJZuTwMWafMiO1bvYpM1ouTsueE4NZxtplkp92idOyl3likLRW0l5Jw5KuLfP8GyXdL2m3pO9JWpF1TGbN1C6T/LRLnJY9RUR2O5dmAD8DLgZGgJ3A5RGxp2ib0yPid8njdcDfRsTaavvt7++PwcHBzOI2y8Kho6NtMclPu8Rp9ZO0KyL6J9su61FJq4HhiNiXBLUNWA88kRgmkkLiNCC7TGWWo3aZ5Kdd4rTsZJ0YFgH7i5ZHgOeXbiTpzcDbgVOBF2cck5mZVZF1H0O5sW4nXRFExJaIeAZwDfDusjuSNkoalDR48ODBBodpZmYTsk4MI8DiouU+4ECV7bcB/63cExGxNSL6I6K/t7e3gSGamVmxrBPDTmC5pGWSTgUuAwaKN5C0vGjxr4CfZxyTWS5avSRGN/FnUV2mfQwRcULSJmAHMAO4KSIekLQZGIyIAWCTpIuAMeAw8NosYzLLQzuUxOgW/iwml+lw1ax4uKq1k0NHR1nzkW9xfOzJm8dmz+zh7mte7NE/Tdbtn0Wtw1V957NZxtqlJEY38GdRGycGs4y51ETr8GdRGycGs4y51ETr8GdRG/cxmDWJS020jm79LFqlJIaZJVxqonX4s6jOTUlmZpbixGBmZilODGZmluLEYGZmKU4MZmaW4sRgZmYpTgxmZpbixGBmZilODGZmluLEYGZmKU4MZmaW4sRgZmYpmScGSWsl7ZU0LOnaMs+/XdIeSUOS7pR0dtYxmZlZZZkmBkkzgC3AJcAK4HJJK0o2uxfoj4iVwG3ADVnGZGZm1WV9xbAaGI6IfRHxB2AbsL54g4i4KyIeSxbvAfoyjsnMzKrIOjEsAvYXLY8k6yp5HfC1TCMys6536Ogo9+0/wqGjo3mH0pKynqhHZdaVnTJO0hVAP/CiCs9vBDYCLFmypFHxmVmXuX33w1yzfYiZPT2MjY9zw4aVrFtV7e/V7pP1FcMIsLhouQ84ULqRpIuAdwHrIqJsCo+IrRHRHxH9vb29mQRrZp3t0NFRrtk+xPGxcR4dPcHxsXGu3j7kK4cSWSeGncByScsknQpcBgwUbyDpPOBTFJLCbzKOx8y62MjhY8zsSX/tzezpYeTwsZwiak2ZJoaIOAFsAnYAPwFujYgHJG2WtC7Z7KPAXOCLknZLGqiwOzOzaembP4ex8fHUurHxcfrmz8kpotaUdR8DEXEHcEfJuvcUPb4o6xjMzAAWzJ3FDRtWcnVJH8OCubPyDq2lZJ4YzMxaybpVi1hzzkJGDh+jb/4cJ4UynBjMrOssmDvLCaEK10oyM7MUJwYzM0txYjAzsxQnBjMzS3FiMDOzFCcGMzNLcWIwM7MUJwYzM0tRRNkq2C1N0kHglzmGsBD4bY7v38p8bKrz8anMx6ayRh2bsyNi0vLUbZkY8iZpMCL6846jFfnYVOfjU5mPTWXNPjZuSjIzsxQnBjMzS3FimJqteQfQwnxsqvPxqczHprKmHhv3MZiZWYqvGMzMLMWJoQpJayXtlTQs6doyz79d0h5JQ5LulHR2HnHmYbJjU7TdKySFpK4ZbVLLsZH0yuTceUDSvzU7xjzV8O9qiaS7JN2b/Nu6NI84m03STZJ+I+nHFZ6XpH9KjtuQpOdmFkxE+KfMDzAD+L/A04FTgfuAFSXb/AXwR8njNwFfyDvuVjk2yXbzgO8A9wD9ecfdKscGWA7cC8xPlp+ad9wtdny2Am9KHq8AHsw77iYdmxcCzwV+XOH5S4GvAQJeAPwgq1h8xVDZamA4IvZFxB+AbcD64g0i4q6IeCxZvAfoa3KMeZn02CTeD9wAHG9mcDmr5di8AdgSEYcBIuI3TY4xT7UcnwBOTx6fARxoYny5iYjvAP9RZZP1wC1RcA9wpqSnZRGLE0Nli4D9RcsjybpKXkchm3eDSY+NpPOAxRHxlWYG1gJqOW+eCTxT0t2S7pG0tmnR5a+W43M9cIWkEeAO4C3NCa3l1fudNGWe87kylVlXdgiXpCuAfuBFmUbUOqoeG0k9wI3Alc0KqIXUct6cQqE56UIKV5nflXRuRBzJOLZWUMvxuRy4OSI+Lul84LPJ8RnPPryWVvN30nT5iqGyEWBx0XIfZS5pJV0EvAtYFxGjTYotb5Mdm3nAucC3JT1IoT10oEs6oGs5b0aA2yNiLCJ+AeylkCi6QS3H53XArQAR8X1gNoVaQd2upu+kRnBiqGwnsFzSMkmnApcBA8UbJM0ln6KQFLqpnbjqsYmIRyJiYUQsjYilFPpf1kXEYD7hNtWk5w3wJQoDF5C0kELT0r6mRpmfWo7PQ8BLACT9CYXEcLCpUbamAeA1yeikFwCPRMSvsngjNyVVEBEnJG0CdlAYSXFTRDwgaTMwGBEDwEeBucAXJQE8FBHrcgu6SWo8Nl2pxmOzA3ippD3A48A7I+JQflE3T43H5x3ApyW9jUJTyZWRDMvpZJI+T6F5cWHSv/JeYCZARHySQn/LpcAw8BjwN5nF0gXH28zM6uCmJDMzS3FiMDOzFCcGMzNLcWIwM7MUJwYzM0txYjAzsxQnBusokh5Mbhqb1jYNiONCSX/ewH3VXHNKUr+kf5pkm6VVyjtfKek/1xundQ4nBrNsXAjUnBgkNeRmU0mnRMRgRLx1Gru5EnBi6GJODJa75K/Xn0r6F0k/lvSvki5Kqo/+XNJqSU+R9KVkgpJ7JK1MXrtA0jeSSV0+RVGhMUlXSPqhpN2SPiVpRsn7nibpq5LuS973r6vEeGkS4/eSyVK+kqw/KS5JS4E3Am9L3vu/VNjnzZI+Ieku4CNJPDdJ2pn8PuVKmZfbz/WStkr6BnBL8RWGpF5J35T0o+QY/LLoammGpE+rMFnQNyTNkfQKCgUh/zWJfU4tMVhncWKwVnEO8I/ASuBZwKuAC4CrgL8H3gfcGxErk+Vbkte9F/heRJxHoZbMEniixs5fA2siYhWF0hOvLnnPtcCBiHhORJwLfL1cYJJmU6iJdUlEXAD0Fj19UlwR8SDwSeDGiFgVEd+t8ns/E7goIt5BoRjjtyLizyjUUvqopNOqvLbY84D1EfGqkvXvTfb5XODfSY5PYjmFeSH+FDgCbIiI24BB4NVJ7MdqfH/rIK6VZK3iFxFxP4CkB4A7IyIk3Q8sBc4GNgBExLeSK4UzKMx69fJk/VclHU729xIKX5Y7kzpWc4DSQof3Ax+T9BHgK1W+wJ8F7EsqoQJ8HtiYPL6gQly1+mJEPJ48fimwTtJVyfJs0l/k1QxU+BK/AHhZEt/Xi44PFI757uTxLgrH2cyJwVpGccny8aLlcQrn6Ykyr4mS/xcT8JmIuK7SG0bEzyQ9j0Jhsg9J+kZEbK6wr0qmWyP/9yX72hARe1NvIJ1V535SL6/ymuJj/jiF5GnmpiRrG98haQqSdCHw24j4Xcn6S4D5yfZ3Aq+Q9NTkuadIOrt4h8nIm8ci4nPAxyjMt1vOT4GnJ30HUGiimiyuRynMS1GPHcBblFziqFDWfbq+B7wy2d9LefL4VDOV2K2DODFYu7ge6Jc0BHwYeG2y/n3ACyX9iEJTzEMAEbEHeDfwjeQ13wRK58d9NvBDSbsptO9/oNwbJ000fwt8XdL3gF8Dj0wS15eBl1XrfC7j/RTKLA8lQ0nfX+PrqnkfhRLfPwIuAX5F4Yu/mpuBT7rzuXu57LZZDSTNjYijyV/zW4CfR8SNecc1GUmzgMeTeRDOB/456Yw3q8h9DGa1eYOk1wKnAvdSGKXUDpYAt6owD/cfgDfkHI+1AV8xmBWR9O/AspLV10TEjmns813Afy9Z/cWI+GCd+/kb4O9KVt8dEW+eamxm5TgxmJlZijufzcwsxYnBzMxSnBjMzCzFicHMzFKcGMzMLOX/A/cNSGEfeuTQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "passive_responses.plot(kind=\"scatter\", x=\"models_got_rel_right\", y=\"got_rel_right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Are correct guesses / errors correlated to informativeness?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mass responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "not_na_passive_responses = passive_responses[passive_responses[\"post_ent\"].notna()]\n",
    "\n",
    "post_mass_correct_guesses = not_na_passive_responses.query(\"model_mass_correct_guesses\")[\"post_ent_mass.rtheta\"]\n",
    "post_mass_wrong_guesses = not_na_passive_responses.query(\"not model_mass_correct_guesses\")[\"post_ent_mass.rtheta\"]\n",
    "\n",
    "f_oneway(post_mass_correct_guesses, post_mass_wrong_guesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "post_mass_correct_guesses = not_na_passive_responses.query(\"corMass == 1\")[\"post_ent_mass.rtheta\"]\n",
    "post_mass_wrong_guesses = not_na_passive_responses.query(\"corMass == 0\")[\"post_ent_mass.rtheta\"]\n",
    "\n",
    "f_oneway(post_mass_correct_guesses, post_mass_wrong_guesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Force responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "post_force_correct_guesses = not_na_passive_responses[not_na_passive_responses.model_force_correct_guesses]['post_ent_rel.rtheta']\n",
    "post_force_wrong_guesses = not_na_passive_responses[~not_na_passive_responses.model_force_correct_guesses]['post_ent_rel.rtheta']\n",
    "\n",
    "f_oneway(post_force_correct_guesses, post_force_wrong_guesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "post_force_correct_guesses = not_na_passive_responses[(not_na_passive_responses.corRel).astype(bool)]['post_ent_rel.rtheta']\n",
    "post_force_wrong_guesses = not_na_passive_responses[~(not_na_passive_responses.corRel).astype(bool)]['post_ent_rel.rtheta']\n",
    "\n",
    "f_oneway(post_force_correct_guesses, post_force_wrong_guesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What percentage of the time does the model match the most common participant answer? second most common? and third?\n",
    "print((passive_responses[\"model_mass\"] == passive_responses[\"resp_mass\"]).sum() / len(passive_responses))\n",
    "print((passive_responses[\"model_mass\"] == passive_responses[\"second_resp_mass\"]).sum() / len(passive_responses))\n",
    "print((passive_responses[\"model_mass\"] == passive_responses[\"third_resp_mass\"]).sum() / len(passive_responses))\n",
    "print()\n",
    "print((passive_responses[\"model_relationship\"] == passive_responses[\"resp_rel\"]).sum() / len(passive_responses))\n",
    "print((passive_responses[\"model_relationship\"] == passive_responses[\"second_resp_rel\"]).sum() / len(passive_responses))\n",
    "print((passive_responses[\"model_relationship\"] == passive_responses[\"third_resp_rel\"]).sum() / len(passive_responses))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
